---
title: "Generics BDA"
output: html_notebook
---


```{r}
library(rwebppl)
library(tidyverse)
library(knitr)
library(purrr)
library(coda)
library(ggthemes)
theme_set(theme_few())
estimate_mode <- function(s) {
  d <- density(s)
  return(d$x[which.max(d$y)])
}
hdi_upper<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","upper"])
}
hdi_lower<- function(s){
  m <- HPDinterval(mcmc(s))
  return(m["var1","lower"])
}
```

```{r}
readData = function(folder, proj){
  read_csv(
    paste("../data/paper_data/",folder,"/",
          proj,"-trials.csv", sep = "")
    )
}

readCatchInfo = function(folder, proj){
  read_csv(
    paste("../data/paper_data/",folder,"/",
          proj,"-catch_trials.csv", sep = "")
    )
}

priorDataLabel = "expt1a-prior"
interpretationDataLabel = "expt1b-interpretation"
```
# Load data

## Load human data
Prior data

```{r}
df.prior <- readData("expt1/", priorDataLabel)
df.prior.catch <- readCatchInfo("expt1/", priorDataLabel)

df.prior.catch.summary <- df.prior.catch %>%
  group_by(workerid, tested_on) %>%
  summarize(totalCorrect = sum(correct)) %>%
  ungroup() %>%
  spread(tested_on, totalCorrect) %>%
  rename(correct_rejection = `0`, 
         hit = `1`) %>%
  mutate(pass = ifelse(hit >= 4 & correct_rejection >= 4, 1, 0),
         totalCorrect = correct_rejection + hit)

df.prior <- left_join(df.prior, df.prior.catch.summary %>%
                         select(workerid, totalCorrect, pass))

df.prior.filtered <- df.prior %>% 
  filter(pass == 1, trial_type == "prevalence_elicitation") %>%
  mutate(response = as.numeric(response))

```

Interpretation (posterior) data

```{r}
df.int.catch <- readCatchInfo("expt1/", interpretationDataLabel)

df.int.catch.summary <- df.int.catch %>%
  group_by(workerid, tested_on) %>%
  summarize(totalCorrect = sum(correct)) %>%
  ungroup() %>%
  spread(tested_on, totalCorrect) %>%
  rename(correct_rejection = `0`, 
         hit = `1`) %>%
  mutate(pass = ifelse(hit >= 4 & correct_rejection >= 4, 1, 0),
         totalCorrect = correct_rejection + hit)

df.int <- readData("expt1/", interpretationDataLabel) %>%
  group_by(workerid) %>%
  mutate(normalizedResponse = (response - mean(response)) / sd(response))

df.int <- left_join(df.int, df.int.catch.summary %>%
                         select(workerid, totalCorrect, pass))

df.int.filtered <- df.int %>% filter(pass == 1) %>%
  mutate(response = as.numeric(response)) %>%
    mutate(property = gsub("&quotechar", "", property))

```

## Load model results

```{r load all model results}
semantics <- c("uncertain")
models <- c("pragmatic", "pragmatic_unlifted")

m.samp <- data.frame()
m.samp.item_params <- data.frame()
m.samp.global_params <- data.frame()
m.samp.predictions <- data.frame()

for (sem in semantics){
  model.path <- paste("../models/results/", sep = "")
  if (sem == "uncertain") { # generics model(s)
      for (modelName in models){
        
        # #  FIXING PRIORS TO BE RAW EMPIRICAL DIISTRIBUUTIONS
        # model.prefix <- paste(
        #   "results-genint-wCost-int6-prior3-fixedPrior-fullDist_", modelName, "-",
        #   sem, "-", sep = "")
        # n_samples <- 50000
        # n_burn <- n_samples / 2
        # lg <- 20         
        
        # FLEXIBLE PRIORS
        model.prefix <- paste(
          "results-genint-wCost-int6-prior3-flexiblePrior-fullDist_", modelName, "-",
           sem, "-", sep = "")
        n_samples <- 400000
        n_burn <- n_samples / 2
        lg <- if (modelName == "pragmatic") { 400 } else { 800 }
        
        model.files <- list.files(
          path = model.path,
          pattern = paste(model.prefix, format(n_samples, scientific = F), 
                          "_burn", format(n_burn, scientific = F), 
                      "_lag", lg, "_chain", sep = "")
        )
        
        m.samp.model <- map_dfr(model.files, function(modfile){
          read_csv(paste(model.path, modfile, sep = "/")) %>%
            mutate(
                src = modelName,
                semantics = sem,
                chain = match(modfile, model.files)
            )
          })
        
        # m.samp <- bind_rows(m.samp, m.samp.model)
        
        
      ## FLEXIBLE PRIOR MODELS GOT WRITTEN OUT IN IDIOSYNCRACTIC WAYS...        
        m.samp.item_params <- bind_rows(m.samp.item_params, m.samp.model %>%
                                     filter(type == "componentParameters") %>%
                                       mutate(property = as.numeric(property)))
        
        m.samp.global_params <- bind_rows(m.samp.global_params, m.samp.model %>%
                                     filter(type == "parameter") %>%
                                       mutate(property = as.numeric(property)))
        
        m.samp.model.predictions <- if (modelName == "pragmatic") {
          m.samp.model %>% filter(type == "prediction") %>%
            rename(submodel = category, category = property, property = param)
        } else {
          m.samp.model %>% filter(type == "prediction") %>%
            rename(submodel = property, property = param) %>%
                      mutate(category = as.numeric(category))
        }
        
        m.samp.predictions <- bind_rows(m.samp.predictions, 
         m.samp.model.predictions  %>%
            mutate(property = gsub("&quotechar", "", property)) %>%
             rename(iteration = iter))
        
        
        
      }
  }

}

# m.samp <- m.samp %>%
#   rename(parameter = category, category = property, property = param) %>%
#   mutate(property = gsub("&quotechar", "", property))


```

# Posterior on parameters


```{r}
#m.samp %>%
m.samp.global_params %>%
  # filter(type %in% c("speakerOptimality","cost", "n_obs")) %>%
  filter(param %in% c("speakerOptimality","cost", "n_obs")) %>%
  ggplot(., aes( x = val, fill = factor(chain)))+
  geom_histogram(position = position_dodge())+
  #facet_grid(type~src + semantics, scales = 'free')
  facet_grid(param~src + semantics, scales = 'free')

# ggsave(paste("figs/", model.prefix, "speakerOptimality.pdf", sep = ""),
#        width = 4, height = 4)
```



```{r}
m.genint.params.l1 <- m.samp %>%
  filter(type %in% c("speakerOptimality","cost")) %>%
  group_by(type, src) %>%
  summarize(MAP = estimate_mode(val),
            cred_upper = hdi_upper(val),
            cred_lower = hdi_lower(val))

#save(m.genint.params.l1, file = "../paper/cached_results/genint_L1_params.RData")
```



# Posterior Predictives

## Implied Prevalence 


### Expected Values (means)

```{r}
#m.samp %>%
m.samp.predictions %>%
  rename(iteration = iter) %>% # FLEXIBLE PRIOR models 
  mutate(src = paste(src, submodel, sep = "_")) %>% # FLEXIBLE PRIOR models
  filter(type == "prediction") %>%
  group_by(iteration, property, src, semantics, chain) %>%
  summarize(expval = sum(category * val)) %>%
  ungroup() %>%
  group_by(property, src, semantics) %>%
  summarize(model_MAP = estimate_mode(expval),
            model_upper = hdi_upper(expval),
            model_lower = hdi_lower(expval)) -> m.pp.expval

df.int.filtered.bs <- df.int.filtered %>%
    #filter(property %in% levels(factor(m.samp$param))) %>%
    group_by(property) %>%
    tidyboot::tidyboot_mean(column = response)


# without literal model
md.impprev <- left_join(
  m.pp.expval,
  df.int.filtered.bs
)

# save(df.int.filtered, df.int.filtered.bs, md.impprev,
#      file = "../paper/cached_results/genInt_interpretation6_prior3_modelData2.RData")
```



#### Model vs. Data

```{r}
ggplot(md.impprev, aes( x = model_MAP, xmin = model_lower, xmax = model_upper, 
                        y = mean, ymin = ci_lower, ymax = ci_upper))+
  geom_abline(intercept = 0, slope = 1, lty = 2)+
  geom_point()+
  geom_errorbar(alpha = 0.3)+
  geom_errorbarh(alpha = 0.3)+
  facet_wrap(~src)+
  #facet_wrap(~category)+
  scale_x_continuous(limits = c(-0.01,1.01), breaks = c(0, 0.5, 1)) +
  scale_y_continuous(limits = c(-0.01,1.01), breaks = c(0, 0.5, 1)) +
  coord_fixed()

# ggsave(paste("figs/", model.prefix, "interpretationScatters.pdf", sep = ""),
#        width = 6, height = 4)
```


#### Model vs. Model

```{r}

myspread <- function(df, key, value) {
    # quote key
    keyq <- rlang::enquo(key)
    # break value vector into quotes
    valueq <- rlang::enquo(value)
    s <- rlang::quos(!!valueq)
    df %>% gather(variable, value, !!!s) %>%
        unite(temp, !!keyq, variable) %>%
        spread(temp, value)
}

m.pp.expval.wide <- m.pp.expval %>% 
  myspread(src, c(model_MAP, model_upper, model_lower))

ggplot(m.pp.expval.wide, 
       aes( y = pragmatic_posterior_model_MAP, 
            ymin = pragmatic_posterior_model_lower, 
            ymax = pragmatic_posterior_model_upper, 
            x = pragmatic_unlifted_pragmatic_unlifted_model_MAP, 
            xmin = pragmatic_unlifted_pragmatic_unlifted_model_lower, 
            xmax = pragmatic_unlifted_pragmatic_unlifted_model_upper))+
  geom_abline(intercept = 0, slope = 1, lty = 2)+
  geom_point()+
  geom_errorbar(alpha = 0.3)+
  geom_errorbarh(alpha = 0.3)+
  #facet_wrap(~category)+
  scale_x_continuous(limits = c(0.25,1.01), breaks = c(0.25, 0.5, 1)) +
  scale_y_continuous(limits = c(0.25,1.01), breaks = c(0.25, 0.5, 1)) +
  coord_fixed()
```


### Full Distributions

```{r}
#m.samp %>%
m.samp.predictions %>%
  rename(iteration = iter) %>% # FLEXIBLE PRIOR models 
  mutate(src = paste(src, submodel, sep = "_")) %>% # FLEXIBLE PRIOR models  
  filter(type == "prediction") %>%
  mutate(state = as.numeric(category)) %>%
  group_by(property, iteration, src, chain) %>%
  arrange(iteration, src, property, state, chain) %>%
  mutate(cumulprob = ave(val, FUN=cumsum)) -> m.samp.cumulProb

m.samp.cumulProb.bs <- m.samp.cumulProb %>%
  ungroup() %>%
  group_by(property, src, state) %>%
  summarize(med = median(cumulprob),
            ci_upper = quantile(cumulprob, 0.975),
            ci_lower = quantile(cumulprob, 0.025))
#  tidyboot_mean(column = cumulprob)
```

#### Visualize ECDFs

```{r fig.width = 10, fig.height = 13}
m.samp.cumulProb.bs %>%
    filter( src %in% c(
    #"pragmatic_posterior", 
      "pragmatic_unlifted_priorDist",
    "pragmatic_unlifted_pragmatic_unlifted", 
                     "pragmatic_unlifted_literal")) %>%
  ggplot(., aes( x = state, y = med, ymin = ci_lower, ymax = ci_upper, group = src, color = src))+
    geom_linerange()+
    geom_line()+
    stat_ecdf(data = df.int.filtered %>% rename(state = response), aes(x = state), color = 'blue', inherit.aes = F)+
    facet_wrap(~property, scales = 'free')+
    scale_x_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1))+
    scale_y_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1))

# ggsave("figs/fulldists_ecdf-unlifted-literal-prior-fullDist-int6-prior3-3Components_uncertain-semantics.pdf", width = 18, height = 10)
#ggsave("figs/fulldists_ecdf-L0-fullDist-int6-prior3-3Components_uncertain-semantics_100000_burn50000_lag100_chain1.pdf", width = 18, height = 10)
```


#### Calculate area between curves

##### ECDF for human data
```{r}
bins <- unique(m.samp.cumulProb.bs$state)
my_ecdf <- function(response){
  #print(row)
  f.ecdf <- ecdf(response)
  data.frame(
    #property = property,
    state = bins, 
    probs = f.ecdf(bins),
    row.names = NULL)
}

df.int.ecdf <- df.int.filtered %>%
  group_by(property) %>%
  group_modify(~my_ecdf(.x$response))

  ggplot(df.int.ecdf, aes( x = state, y = probs))+
    geom_line()+
    stat_ecdf(data = df.int.filtered %>% rename(state = response), aes(x = state), color = 'blue', inherit.aes = F)+
    facet_wrap(~property, scales = 'free')+
    scale_x_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1))+
    scale_y_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1))
```

##### Differences between model CDF and human ECDF

```{r}
left_join(
  m.samp.cumulProb.bs, 
  df.int.ecdf %>% rename(human_ecdf = probs)
) %>%
  mutate(delta = med - human_ecdf,
         abs_delta = abs(delta),
         sq_delta = delta^2) %>%
  group_by(property, src) %>%
  summarize(
    total_delta = sum(delta),
    total_abs_delta = sum(abs_delta),
    total_sq_delta = sum(sq_delta)
  ) -> md.cdf.delta


md.cdf.delta %>%
  gather(key, val, total_delta, total_abs_delta, total_sq_delta) %>%
  ggplot(., aes (x = val, fill = src))+
  geom_histogram(position = position_dodge())+
  facet_wrap(~key, scales = 'free')

md.cdf.delta %>%
  filter( src %in% c(
    #"pragmatic_posterior", 
    "pragmatic_unlifted_pragmatic_unlifted", 
                     "pragmatic_unlifted_literal")) %>%
  gather(key, val, total_delta, total_abs_delta, total_sq_delta) %>%
  ggplot(., aes (x = val, fill = src))+
  geom_density(alpha = 0.5)+
  facet_wrap(~key, scales = 'free')

ggsave("figs/fulldists_ecdf_deltas_overItems-unlifted-literal_fullBayes.pdf", width = 8, height = 4)
```


#### Vizualise PDFs

```{r}
m.samp.predictions %>%
  rename(iteration = iter) %>% # FLEXIBLE PRIOR models 
  mutate(src = paste(src, submodel, sep = "_")) %>% # FLEXIBLE PRIOR models  
  filter(type == "prediction") %>%
  mutate(state = as.numeric(category)) %>%
  group_by(property, src, state) %>%
  summarize(MAP = estimate_mode(val),
            cred_upper = hdi_upper(val),
            cred_lower = hdi_lower(val)) %>%
  mutate(scaled_map = MAP / max(MAP),
         scaled_lower = cred_lower / max(MAP),
         scaled_upper = cred_upper / max(MAP)) -> m.pdf.summary


m.samp.predictions %>%
  rename(iteration = iter) %>% # FLEXIBLE PRIOR models 
  mutate(src = paste(src, submodel, sep = "_")) %>% # FLEXIBLE PRIOR models  
  filter(type == "prediction") %>%
  mutate(state = as.numeric(category)) %>%
  rename(prob = val) %>%
  rwebppl::get_samples(., num_samples = 10) -> m.samp.predictions.samples


my_density <- function(response, adjust = 1){
  f.dens <- density(response,
                  from = 0, to = 1, n = 30, adjust = adjust)
  data.frame(
    state = f.dens$x, 
    dens = f.dens$y,
    scaled.dens = f.dens$y/max(f.dens$y),
    row.names = NULL)
}

m.int.pdf.density <- m.samp.predictions.samples %>%
  group_by(property, src) %>%
  group_modify(~my_density(.x$state, adjust = 4))

df.int.pdf.density <- df.int.filtered %>%
  group_by(property) %>%
  group_modify(~my_density(.x$response))

```

```{r}
bind_rows(m.int.pdf.density,
  df.int.pdf.density %>% mutate(src = 'human data')) -> md.pdf.summary
```


```{r densities all properties}
bind_rows(
  m.pdf.summary,
  df.int.pdf.density %>%
    mutate(src = 'human data',
           scaled_upper = scaled.dens, 
           scaled_lower = scaled.dens,
           cred_upper = dens, cred_lower = dens) %>% 
    rename(scaled_map = scaled.dens, MAP = dens)
) -> md.pdf.summary
  
md.pdf.summary %>%
  filter( src %in% 
            c("human data", 
    "pragmatic_unlifted_pragmatic_unlifted", 
                     "pragmatic_unlifted_literal")) %>%
  ggplot(., aes (x = state, y = scaled_map, ymin = scaled_lower, ymax = scaled_upper,
                 color = src, group = src))+
  geom_line()+
  #geom_linerange()+
  facet_wrap(~property, scales = 'free')

ggsave("figs/fulldists_pdf-unlifted-literal-fullDist-scaledDens-int6-prior3-3Components_uncertain-semantics.pdf", width = 18, height = 10)
```


```{r densities select properties}

properties.of.interest <- c("get addicted to nicotine", "eat people", "drink soda", "perform in the circus", "transmit HIV", "ride the subway", "eat grass", "get in fights with other animals", "capture other animals territory", "get strange genetic mutations", "mourn their dead", "sleep during the day", "swim in shallow pools")
md.pdf.summary %>%
  filter( src %in% 
            c("human data", 
    "pragmatic_unlifted_pragmatic_unlifted",# "pragmatic_unlifted_priorDist",
                     "pragmatic_unlifted_literal"),
    property %in% properties.of.interest) %>%
  #ggplot(., aes (x = state, y = scaled_map, ymin = scaled_lower, ymax = scaled_upper,
  # ggplot(., aes (x = state, y = MAP, ymin = cred_lower, ymax = cred_upper,
  #                color = src, group = src))+
  ggplot(., aes (x = state, y = dens, fill = src,
                 color = src, group = src))+
  geom_area(aes(fill=src), alpha = 0.3, position = 'identity') +
  geom_line(position = position_dodge(0.02), size = 1)+
  #geom_linerange()+
  facet_wrap(~property, scales = 'free')#+
  #scale_y_continuous(limits = c(-0.01, 1.01), breaks = c(0, 0.5, 1))

# ggsave("figs/fulldists_pdf-unlifted-literal-fullDist-scaledDens-int6-prior3-3Components_uncertain-semantics.pdf", width = 18, height = 10)

ggsave("figs/fulldists_12properties_pdf-unlifted-literal-fullDist-scaledDens-int6-prior3-3Components_uncertain-semantics.pdf", width = 12, height = 6)
```

Weaker
get addicted to nicotine
eat people
drink soda
perform in the circus
transmit HIV
ride the subway
Stronger
eat grass
get in fights with other animals
capture other animals territory
get strange genetic mutations
mourn their dead
sleep during the day
swim in shallow pools

# Posterior on item parameters

## Posterior predictive on prevalence priors

```{r}
lower_bins <-seq(0, 0.95, 0.05)
upper_bins <- seq(0.05, 1, 0.05)
mid_bins <- (upper_bins - lower_bins)/2 + lower_bins

round_to_bin <- function(x){
  index <- if (x==0){ 1 } else if (x ==1){ length(mid_bins)} else{
    x <= upper_bins & x > lower_bins
  }
  #if (sum(index) > 1) { print (x) }
  return (mid_bins[index])
}

literal_generic <- function(ps){
  theta_bins <- seq(0.001, 0.99, 0.01)
  data.frame(
    prior_name = ps$prior_name,
    x = bins,
    prior =  ps$mix * dbeta(bins, shape1 = ps$params$c1$a, shape2 =  ps$params$c1$b, log = F) + 
      (1 -  ps$mix) * dbeta(bins, shape1 = ps$params$c2$a, shape2 =  ps$params$c2$b, log = F),
    cdf =  ps$mix * pbeta(theta_bins, shape1 =  ps$params$c1$a, shape2 = ps$params$c1$b, lower.tail = T, log.p = F) + 
      (1 -  ps$mix) * pbeta(theta_bins, shape1 =  ps$params$c2$a, shape2 = ps$params$c2$b, lower.tail = T, log.p = F)
  ) %>%
    dplyr::mutate(
      unnorm_posterior_theta = 1 - cdf,
      norm_posterior_theta = 100*(unnorm_posterior_theta / sum(unnorm_posterior_theta)),
      unnorm_posterior_r = prior*x,
      norm_posterior_r = 100*(unnorm_posterior_r / sum(unnorm_posterior_r))
    )
}


pdf_mixture <- function(row){
  data.frame(
    iter = row$iter,
    property = row$property,
    src = row$src,
    semantics = row$semantics,
    chain = row$chain,
    lower_bin = lower_bins,
    upper_bin = upper_bins
  ) %>%
    mutate(
      mid_bin = lower_bin + (upper_bin - lower_bin)/2,
      pdf = row$weight_0 * dbeta(mid_bin, shape1 = row$alpha_0, shape2 = row$beta_0) +
        row$weight_1 * dbeta(mid_bin, shape1 = row$alpha_1, shape2 = row$beta_1) +
        row$weight_2 * dbeta(mid_bin, shape1 = row$alpha_2, shape2 = row$beta_2)
    )
}

m.samp.item_params.wide <- m.samp.item_params %>% 
  rename(parameter = category, componentID = property, property = param) %>%
  mutate(componentParam = paste(parameter, "_", componentID, sep = "")) %>% select(-componentID, -parameter) %>%
  spread(componentParam, val)


# purrr::map_dfr(1:nrow(m.samp.item_params.wide),
#   ~ pdf_mixture(m.samp.item_params.wide[.x, ])) -> m.samp.item_priors

```


```{r}
m.samp.item_params %>%
  group_by(type, param, property, category, src, semantics, chain) %>%
  summarize(
    MAP = estimate_mode(val), cred_upper = hdi_upper(val), cred_lower = hdi_lower(val)
  ) -> m.item_param.summary
```


```{r}


df.int.filtered.i <- df.int.filtered %>% 
  group_by(property) %>%
  #sample_n(53, replace = TRUE) %>%
  rowwise() %>%
  mutate(binned_response = round_to_bin(response)) %>%
  group_by(property, binned_response) %>%
  count() %>%
  ungroup() %>%
  spread(binned_response, n)

df.int.filtered.i[is.na(df.int.filtered.i)] <- 0

df.int.filtered.i %>%
  gather(state, n, -property) %>%
  group_by(property) %>%
  mutate(prop = n / sum(n),
         prop = round(prop, 5)) -> df.int.pdf.summary



```

```{r}
f.dens <- density(df.int.filtered %>% filter(property == "get dandruff") %>% pull(response),
                  from = 0, to = 1, n = 30)
f.dens$f.dens(bins)
```


Check  that total probs are actually equalling 1

```{r}
m.samp.iter.totalProb <- m.samp.iter %>%
  mutate(state = as.numeric(state)) %>%
  group_by(property, iteration) %>%
  arrange(iteration, property, state) %>%
  summarize(totalProb = sum(val))
```


### Prevalence prior parameters

#### Forward sample prevalence priors

Add iteration number back in.

```{r}
m.samp.iter <- m.samp %>%
  #filter(type %in% c("componentParameters")) %>%
  filter(parameter %in% c("weight", "alpha", "beta")) %>%
  # mutate(parameter = paste(type, param, property, category, sep = "_")) %>%
  # select(-type, -param, -property, -category) %>%
  mutate(parameter = paste(parameter, property, component, sep = "_")) %>%
  select(-property, -component) %>%
  group_by(parameter) %>%
  mutate(iteration = ave(parameter==parameter, parameter, FUN=cumsum)) %>%
  ungroup() %>%
#  separate(parameter, into = c("parameter", "property", "componentID", "componentParam"), sep= "_")
  separate(parameter, into = c("parameter", "property", "componentID"), 
           sep= "_")

m.rs.prior.parameters <- m.samp.iter %>% 
  #mutate(componentParam = paste(componentParam, "_", componentID, sep = "")) %>% select(-componentID) %>%
  mutate(componentParam = paste(parameter, "_", componentID, sep = "")) %>% select(-componentID, -parameter) %>%
  spread(componentParam, val) %>%
  rowwise() %>%
  mutate(component = LaplacesDemon::rcat(1, c(`weight_0`, `weight_1`, `weight_2`)) - 1,
         shape1_param = ifelse(component == 0, alpha_0, ifelse(component == 1, alpha_1, alpha_2)),
         shape2_param = ifelse(component == 0, beta_0, ifelse(component == 1, beta_1, beta_2)),
         prev = rbeta(shape1 = shape1_param, shape2 = shape2_param, n = 1))

```

##### Marginal distributions on prevalence

```{r gen-prevprior2-marginals, fig.width = 8, fig.height = 5}
md.prevpriors <- bind_rows(
  df.prior.filtered %>% 
    filter(property %in% levels(factor(m.rs.prior.parameters$property))) %>%
    select(property, response) %>%
    rename(prev = response) %>% 
    mutate(src = 'data'),
  m.rs.prior.parameters %>% 
    select(property, prev, src) %>%
    mutate(src = paste(src, semantics, sep = "_")) 
  )

ggplot(md.prevpriors , aes( x = prev, color = src))+
  geom_density(size = 1, aes( y = ..scaled.. ), adjust = 0.5)+
  facet_wrap( ~ property)+
  scale_color_solarized()+
  scale_x_continuous(limits = c(0,1), breaks = c(0, 0.5, 1)) +
  scale_y_continuous(limits = c(0,1), breaks = c(0, 0.5, 1)) +
  theme(strip.text.y = element_text(angle = 0))

# ggsave(paste("figs/", model.prefix, "prevPriorsPDFs.pdf", sep = ""),
#        width = 14, height = 8)
```

##### Cumulative Density Functions

```{r gen-prevprior2-cdf, fig.width = 8, fig.height = 5}
fig.prevprior.cdf.collapse <- ggplot(md.prevpriors, aes( x = prev, color = src))+
    stat_ecdf()+
    facet_wrap(~property)+
    #scale_color_solarized()+
    scale_x_continuous(limits = c(-0.01,1.01), breaks = c(0, 0.5, 1)) +
    scale_y_continuous(limits = c(-0.01,1.01), breaks = c(0, 0.5, 1)) +
    theme(strip.text.y = element_text(angle = 0))+
    coord_fixed()

ggsave(paste("joint_prevPriorsCDFs.pdf", sep = ""),
       width = 5.5, height = 3.5)

ggsave(paste("individual_prevPriorsCDFs.pdf", sep = ""),
       width = 14, height = 8)
```

```{r wip}
m.samp.iter.weight <- m.samp.iter %>%
  filter((componentParam == "weight") | (parameter == "numberOfComponents")) %>%
  mutate(componentID = paste("component", componentID, sep = "")) %>%
  spread(componentID, val)

m.samp.iter.param <- m.samp.iter %>%
  filter(componentParam %in% c("alpha", "beta")) %>%
  spread(componentParam, val)

# for (p in levels(factor(m.samp.iter$property))){
#   for (i in seq(1, n_samples){
#     
#   }
# }
# 
# m.samp.iter.weight.i <- m.samp.iter.weight %>% 
  filter(iteration == 10, property == 'develop phobias')

indices <- paste("component", 
                 seq(0, 
                     filter(m.samp.iter.weight.i, 
                            parameter == 'numberOfComponents')[[1, "component-99"]]), 
                 sep ="")

ps <- as.numeric(as.vector(
  filter(m.samp.iter.weight.i, 
         componentParam == 'weight')[1,indices]
  ))

componentId <- LaplacesDemon::rcat(1, ps)

m.samp.iter.param %>%
  filter(property == p, iteration == i, componentID == componentId) %>%
  mutate(prev = rbeta(shape1 = alpha, shape2 = beta, n = 1))

```


## Model comparison

```{r}
mll.results.path <- "../models/results/genint/marginal_likelihood/final_results/"
mll.results = list.files(
  path = mll.results.path,
  # pattern = paste(model.prefix, format(n_samples, scientific = F), 
  #                 "_burn", n_burn, 
  #             "_lag", lg, "_chain", sep = "")
)
extractMLLfromJSON <- function(fileName){
  name1 <- strsplit(fileName, "-")[[1]][4]
  name2 <- strsplit(fileName, "-")[[1]][5]
  rs <- jsonlite::fromJSON(paste(mll.results.path, fileName, sep = ""))[1]
  return(data.frame(name1=name1, name2=name2, mll=rs))
}

rs.mll <- bind_rows(lapply(mll.results, extractMLLfromJSON)) %>%
  mutate(name2 = ifelse(name1 == "steps2000","generic", name2))

rs.mll.formatted <- rs.mll %>%
  group_by(name1, name2) %>%
  summarize(mll = mean(mll)) %>%
  ungroup() %>%
  mutate(Model = ifelse(name2 == "most", '"Most"',
                  ifelse(name1 == "prior", "Prior", 
                 ifelse(name2 == "some", '"Some"',
                ifelse(name1 == "pragmatic_unlifted", 
                       "Pragmatic Generic",
                 ifelse(name2 == "generic", "Literal Generic", name1)))))) %>%
  filter(!Model == "pragmatic") %>%
  select(Model, mll)

save(rs.mll.formatted, file = "../paper/cached_results/genint_BF_results.RData")
```




