// time ~/webppl-fork/webppl generics-bda.wppl --require utils

var chain = last(process.argv) // load index as last command line index

// penultimate argument is the semantics
// causal = uncertain threshold
// some = fixed threshold at lowest threshold value
var targetUtterance = process.argv[process.argv.length - 2]

var dataPath = "../data/",
    priorFilePrefix = "prior-1",
    interpretationFilePrefix = "interpretation-3"

var priorFile = dataPath + "prior/"+priorFilePrefix+"/"+priorFilePrefix+"-trials.csv",
    priorCatchFile = dataPath + "prior/"+priorFilePrefix+"/"+priorFilePrefix+"-catch_trials.csv",
    interpretationFile = dataPath + "interpretation/"+interpretationFilePrefix+"/"+interpretationFilePrefix+"-trials.csv",
    interpretationCatchFile = dataPath + "interpretation/"+interpretationFilePrefix+"/"+interpretationFilePrefix+"-catch_trials.csv";

var d_prior = dataFrame(utils.readCSV(priorFile).data, ["workerid","response"]),
    d_prior_catch = dataFrame(utils.readCSV(priorCatchFile).data, ["workerid",  "correct"]),
		d_interpretation = dataFrame(utils.readCSV(interpretationFile).data, ["workerid", "response"]),
    d_interpretation_catch=dataFrame(utils.readCSV(interpretationCatchFile).data, ["workerid", "correct"]);

var priorWorkerids = levels(d_prior_catch, "workerid")
var interpretationWorkerids = levels(d_interpretation_catch, "workerid")

var priorWorkeridsPassed = filter(function(workerid){
  sum(_.map(_.filter(d_prior_catch, {workerid: workerid}), "correct")) >= 8
}, priorWorkerids)

var interpretationWorkeridsPassed = filter(function(workerid){
  sum(_.map(_.filter(d_prior_catch, {workerid: workerid}), "correct")) >= 8
}, interpretationWorkerids)

var data = {
	prior: filter(function(di){
    return priorWorkeridsPassed.indexOf(di.workerid) > -1
  }, map(function(d){ return extend(d, {
		avoided_endval: avoidEnds(d.response)
  })}, d_prior)),
	interpretation: filter(function(di){
    return interpretationWorkeridsPassed.indexOf(di.workerid) > -1
  }, map(function(d){ return extend(d, {
		binnedResponse:  utils.closest( midBins.slice(1), d.response)
	})}, d_interpretation))
};

// // test that removing Ss who failed catch trial works properly
assert.ok(levels(data.interpretation, "workerid").length == interpretationWorkeridsPassed.length)

assert.ok(levels(data.prior, "workerid").length == priorWorkeridsPassed.length)


var utterancePrior = Infer({model: function(){
	return uniformDraw(["generic", "silence"])
}});

var meaning = function(utt,state, theta) {
  return utt=="generic"? state > theta :
         utt=="generic is false"? state<=theta :
         utt=='silence'? true :
         utt=='some'? state > 0 :
         true
}
//
var properties = levels(data.interpretation, "property");
var nullParams = {a:1, b:100}, nullDistribution = Beta(nullParams);
// properties

var model = function(priorData, interpretationData, item){

  var numberOfComponents = 3;//poisson(1) + 1;

  var weights = normalize(repeat(numberOfComponents,
    function(){ return uniformDrift({a: 0, b: 1, width:0.2}) }
  ))

  var componentParameters = repeat(numberOfComponents,
   function(){
    return betaShape({
        g: uniformDrift({a: 0, b: 1, width: 0.2}),
        d: uniformDrift({a: 0, b: 100, width: 5})
      })
  })

	mapData({data: priorData}, function(d){
    var componentLogLikelihood = map2(function(w, params){
      Math.log(w) + Beta(params).score(d.avoided_endval)
    }, weights, componentParameters)
    var scr = util.logsumexp(componentLogLikelihood)
    // console.log(scr)
		factor(scr)
	})

	var statePrior = Infer({model: function(){
    sample(DiscretizedBeta(componentParameters[discrete(weights)]))
	}});

	/// RSA model
	var listener0 = cache(function(utterance) {
	  Infer({model: function(){
	    var state = sample(statePrior), theta = sample(thetaPrior);
	    var m = meaning(utterance, state, theta)
	    condition(m)
	    return state
	 }})}, 10000)

   var interpretationPrediction = listener0("generic")

   mapData({data:interpretationData}, function(d){
     // display(d)
     // var scr = interpretationPrediction.score(d.binnedResponse)
     // scr == -Infinity ? displayObj(d) : null
     // display(scr)
     observe(interpretationPrediction, d.binnedResponse)
   })

   // RECORD PARAMETERS AND PREDICTIVES
   // query.add("numberOfComponents", [-99, -99, -99, numberOfComponents])
   query.add(["numberOfComponents", item, -99, -99], numberOfComponents)

   foreach(_.range(numberOfComponents), function(i){

     query.add(["componentParameters", item, i, "weight"],
       weights[i]
     )
     query.add(["componentParameters", item, i, "alpha"],
       componentParameters[i]["a"]
     )

     query.add(["componentParameters", item, i, "beta"],
       componentParameters[i]["b"]
     )

   })

  // query.add("prediction", [-99, -99, expectation(statePrior), expectation(interpretationPrediction)])
  query.add(["prediction", item, -99, "prior"], expectation(interpretationPrediction))
  query.add(["prediction", item, -99, "posterior"], expectation(interpretationPrediction))

	return query
}

var totalIterations = 100, lag = 2;
var samples = totalIterations/lag, burn = totalIterations / 2;

// var item = properties[0]
//
// var outfile = 'pilot-results-genint-L0-inferNComponents_'+ totalIterations+'_burn'+burn+'_lag'+lag+'_chain'+chain+'_' + item.split(' ').join('_') +'.csv'
//
// var propertyData = {
//     prior: _.filter(data.prior, {property: item}),
//     interpretation: _.filter(data.interpretation, {property: item})
// };
//
// var posterior = Infer({
//   model: function(){
//     model(propertyData.prior, propertyData.interpretation, item)
//   },
//   method: "MCMC", samples, burn, verbose: true
// })
//
// display("wrote " + outfile)

foreach(properties.slice(0, 3), function(item){

  var outfile = 'pilot-results-genint-L0- 3Components_'+ totalIterations+'_burn'+burn+'_lag'+lag+'_chain'+chain+'_' + item.split(' ').join('_') +'.csv'

  var propertyData = {
      prior: _.filter(data.prior, {property: item}),
      interpretation: _.filter(data.interpretation, {property: item})
  };

  var posterior = Infer({
    model: function(){
      model(propertyData.prior, propertyData.interpretation, item)
    },
    method: "MCMC", samples, burn, verbose: true
  })

  utils.writeQueryERP(posterior, "results/" + outfile,
  ["parameter","property","componentID","componentParam","val"])

  display("wrote " + outfile)
})
