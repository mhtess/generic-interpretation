// time webppl generics-bda-L1-btstrp-likelihoods.wppl --require utils --require webppl-json uncertain 1

var chain = last(process.argv) // load index as last command line index

var bootstrappedPriors = json.read('generics-bda-priormanip-btstrp-priors.json')
var interpretationCounts = json.read('generics-bda-L0-interpretations-counts.json')
var iterations = levels(bootstrappedPriors, "i")
var priorsNames = levels(bootstrappedPriors, "distribution")

// var chunkLength = 1000
// var chunks = _.range(5000, iterations.length, chunkLength)
// var sampleFromPrior = 0.001;
// var sampleFromPrior = 0.15;
var sampleFromPrior = 0.2;

// run in chunks to parallelize and decrease file sizes
var resultsHandle = utils.openFile("results/bootstrap/generics-bda-L1unlifted-btstrpPriors-likelihood-results_sampleFromPriorProb"+sampleFromPrior+".csv")
utils.writeLine(resultsHandle, ["model", "distribution", "iteration", "likelihood"])

foreach(iterations, function(i){

  var iterationPriors = _.filter(bootstrappedPriors, {i: i})

  foreach(priorsNames, function(distribution){
    var distributionPriorsObj = _.filter(iterationPriors, {distribution: distribution} )[0]
    var distributionPriors = _.omit(distributionPriorsObj, ["distribution", "i"])


    var distributionIntObj = _.filter(interpretationCounts, {distribution: distribution} )[0]
    var distributionInt= _.omit(distributionIntObj, ["distribution"])

    var vs = sort(map(function(x){utils.wpParseFloat(x)}, _.keys(distributionPriors)))
    var ps = map(function(v){distributionPriors[v]}, vs)
    var data_counts = map(function(v){distributionInt[v]}, vs)


    var statePrior = Infer({model: function(){ categorical({vs, ps}) } })

    // var addNoise = function(dist){
    //   return Infer({
    //     model: function(){
    //       flip(noiseParam) ? uniformDraw(vs) : sample(dist) }
    //     })
    // }


    // var listener = function(threshold) {
    //   Infer({model: function(){
    //   var state = sample(statePrior)
    //   var theta = threshold ? threshold : sample(thetaPrior)
    //   condition( flip(sampleFromPrior) ? true : state > theta)
    //   return state
    // }})}
    // MAP estimates taken from expt 2
    var cost = 3.6
    var speakerOptimality = 2;
    var cost_uttProb = Math.exp(-cost)

    var listener0 = function(utterance, threshold) {
      Infer({model: function(){
      var state = sample(statePrior)
      var theta = threshold ? threshold : sample(thetaPrior)
      condition( utterance == "generic" ? state > theta : true )
      return state
    }})}

    var speaker1 = cache(function(state) {
     Infer({model: function(){
       var utterance = categorical({vs: ["generic", "silence"], ps: [cost_uttProb, 1]})
       var L0 = listener0(utterance, false);
       factor(speakerOptimality * L0.score(state))
       return utterance
     }})}, 10000)

   var listener1 = cache(function(utterance) {
     Infer({model: function(){
       var state = sample(statePrior);
       var S1 = speaker1(state)
       flip(sampleFromPrior) ? null : observe(S1, utterance)
       return state
     }})}, 10000)

    var all_thresholds = [false, 0.05, 0.125, 0.375, 0.625, 0.875]
    // console.log(data_counts)
    var priorLikelihood = Multinomial({
        ps: normalize(ps),
        n: sum(data_counts)
    }).score(data_counts)

    utils.writeLine(resultsHandle, ["prior", distribution, i, priorLikelihood])

    // foreach(all_thresholds, function(t){

      var posterior = listener1("generic")

      var posteriorProbs = map(function(v){ Math.exp(posterior.score(v)) }, vs)

      var modelLikelihood = Multinomial({
        ps: posteriorProbs,
        n: sum(data_counts)
      }).score(data_counts)

      // var modelName = t ? "fixed_" + t : "uncertain"
      var modelName = "pragmatic_unlifted"

      utils.writeLine(resultsHandle, [modelName, distribution, i, modelLikelihood])

    // })

  })

  if ((i % iterations.length/10) == 0) {
    console.log("iteration = " + i + " complete")
  }

})

utils.closeFile(resultsHandle)
