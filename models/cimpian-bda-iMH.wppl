// time ~/tools/webppl-fork/webppl cimpian-bda-L0-iMH.wppl --require utils pragmatic_unlifted uncertain 1
// time ~/tools/webppl-fork/webppl cimpian-bda-L0-iMH.wppl --require utils pragmatic uncertain 1
// time ~/tools/webppl-fork/webppl cimpian-bda-L0-iMH.wppl --require utils literal uncertain 1

var chain = last(process.argv) // load index as last command line index

// penultimate argument is the semantics
// uncertain = uncertain threshold
// fixed = fixed threshold at lowest threshold value
var modelName = process.argv[process.argv.length - 3]
var semantics = process.argv[process.argv.length - 2]

var AllNullDistributions = [
  {name: "delta", dist: Delta({v: _.min(midBins)})},
  {name: "beta1_100", dist: DiscretizedBeta({a:1, b:100})},
  {name: "beta1_1000", dist: DiscretizedBeta({a:1, b:1000})}
]

var NullDistributionObj = AllNullDistributions[(chain-1) % AllNullDistributions.length]
var NullDistribution = NullDistributionObj.dist;
var NullDistributionName = NullDistributionObj.name;

console.log("model = " + modelName+ " ___ semantics = " + semantics + " ___ null dist = " + NullDistributionName)

var dataPath = "../data/asymmetry/",
    priorFilePrefix = "asymmetry-prior-4",
    interpretationFilePrefix = "implied-prevalence-2"

var priorFile = dataPath + priorFilePrefix+"-trials.csv",
    interpretationFile = dataPath + interpretationFilePrefix+"-trials.csv";

var d_prior = dataFrame(utils.readCSV(priorFile).data, ["workerid","response0", "response1"]),
		d_interpretation = dataFrame(utils.readCSV(interpretationFile).data, ["workerid", "response"]);

var priorWorkerids = levels(d_prior, "workerid")
var interpretationWorkerids = levels(d_interpretation, "workerid")

var data = {
	prior: map(function(d){ return extend(d, {
		response0_avoidedEndval: avoidEnds(d.response0),
    response1_avoidedEndval: avoidEnds(d.response1)
  })}, d_prior),
	interpretation: map(function(d){ return extend(d, {
		binnedResponse:  utils.closest( midBins.slice(1), d.response)
	})}, d_interpretation)
};


var utterancePrior = Infer({model: function(){
	return uniformDraw(["generic", "silence"])
}});

var meaning = function(utt,state, theta) {
  return utt=="generic" ? state > theta :
         utt=="generic is false" ? state<=theta :
         utt=='silence'? true :
         utt=='some'? state > _.min(thetaBins) :
         utt=='most'? state > 0.5 :
         true
}
//
var properties = levels(data.interpretation, "stim_property");


var fixedThreshold = (semantics == "some") ?_.min(thetaBins) :
  (semantics == "most") ? 0.5 :
  false


// properties

var addNoise = function(dist, noise){
  return Infer({model: function(){
    return flip(noise) ? uniformDraw(midBins) : sample(dist)
  }})
}

var model = function(){

    // var fixedThreshold = semantics == "fixed" ? uniformDraw(thetaBins) : -99
    var noise = (semantics == "most") ? uniformDrift({a: 0, b: 1, width:0.2}) : 0
    var speakerOptimality = (modelName == "literal") ? 1 : uniform(0, 30)
    var cost_uttProb = 1//uniformDrift({a: 0, b: 1, width: 0.2})

    var nullParams = betaShape({
      g: uniformDrift({a: 0, b: 0.1, width: 0.01}),
      d: uniformDrift({a: 0, b: 500, width: 50})
    })


  foreach(properties, function(item){
    // display(item)
    var propertyData = {
        prior: _.filter(data.prior, {stim_property: item}),
        interpretation: _.filter(data.interpretation, {stim_property: item})
    };

    var mixture_params = betaShape({
          g: uniformDrift({a: 0, b: 1, width: 0.2}),
          d: uniformDrift({a: 0, b: 100, width: 5})
    })

    mapData({data: propertyData.prior}, function(d){
      observe( Beta(mixture_params), d.response0_avoidedEndval )
    })

    var prevalence_when_present = betaShape({
          g: uniformDrift({a: 0, b: 1, width: 0.2}),
          d: uniformDrift({a: 0, b: 100, width: 5})
    })

    mapData({data: propertyData.prior}, function(d){
      observe( Beta(prevalence_when_present), d.response1_avoidedEndval )
    })

    query.add(["prevPriorParams", item, "mixtureParam", "alpha"], mixture_params.a)
    query.add(["prevPriorParams", item, "mixtureParam", "beta"], mixture_params.b)

    query.add(["prevPriorParams", item, "prevWhenPresent", "alpha"], prevalence_when_present.a)
    query.add(["prevPriorParams", item, "prevWhenPresent", "beta"], prevalence_when_present.b)

  	var statePrior = Infer({model: function(){
      sample(
        flip(sample(DiscretizedBeta(mixture_params))) ?
        DiscretizedBeta(prevalence_when_present) :
        NullDistribution
      )
  	}});

     /// RSA model
   	var listener0 = cache(function(utterance) {
   	  Infer({model: function(){
   	    var state = sample(statePrior);
         var theta = (semantics == "uncertain") ? sample(thetaPrior) : fixedThreshold;
   	    var m = meaning(utterance, state, theta)
   	    condition(m)
   	    return state
   	 }})}, 10000)

      /// LIFTED PRAGMATIC
    	var listener0_forL1 = cache(function(utterance, theta) {
    	  Infer({model: function(){
    	    var state = sample(statePrior);
    	    var m = meaning(utterance, state, theta)
    	    condition(m)
    	    return state
    	 }})}, 10000)

      var speaker1 = cache(function(state, theta) {
       Infer({model: function(){
         var utterance = categorical({vs: ["generic", "silence"], ps: [cost_uttProb, 1]})
         var L0 = listener0_forL1(utterance, theta);
         factor(speakerOptimality * L0.score(state))
         return utterance
       }})}, 10000)

     var listener1 = cache(function(utterance) {
       Infer({model: function(){
         var state = sample(statePrior);
         var theta = (semantics == "uncertain") ? sample(thetaPrior) : fixedThreshold;
         var S1 = speaker1(state, theta)
         observe(S1, utterance)
         return state
       }})}, 10000)

       /// UNLIFTED PRAGMATIC

        var speaker1_unlifted = cache(function(state) {
         Infer({model: function(){
           var utterance = categorical({vs: ["generic", "silence"], ps: [cost_uttProb, 1]})
           var L0 = listener0(utterance);
           factor(speakerOptimality * L0.score(state))
           return utterance
         }})}, 10000)

       var listener1_unlifted = cache(function(utterance) {
         Infer({model: function(){
           var state = sample(statePrior);
           var S1 = speaker1_unlifted(state)
           observe(S1, utterance)
           return state
         }})}, 10000)

    var L = modelName == "literal" ? listener0("generic") :
    modelName == "unlifted_pragmatic" ? listener1_unlifted("generic") :
    listener1("generic")

    var interpretationPrediction = addNoise(L, noise)

   mapData({data:propertyData.interpretation}, function(d){
     // display(d)
     var scr = interpretationPrediction.score(d.binnedResponse)
     scr == -Infinity ? displayObj(d) : null
     // display(scr)
     observe(interpretationPrediction, d.binnedResponse)
   })

   query.add(["prediction", item, -99, "prior"], expectation(statePrior))
   query.add(["prediction", item, -99, "posterior"], expectation(interpretationPrediction))
 })

  // query.add(["prevPriorParams", -99, "nullParams", "alpha"], nullParams.a)
  // query.add(["prevPriorParams", -99, "nullParams", "beta"], nullParams.b)

   // RECORD PARAMETERS AND PREDICTIVES
   // query.add("numberOfComponents", [-99, -99, -99, numberOfComponents])
   semantics == "most" ? query.add(["noise", -99, -99, -99], noise) : null
   modelName == "literal"? null: query.add(["optimality", -99, -99, -99], speakerOptimality)

	return query
}

var totalIterations = 250, lag =  1;
var samples = totalIterations/lag, burn = totalIterations / 2;

var outfile = 'results-cimpian-'+modelName+'-structuredPrior_'+semantics+'-semantics-nullDist_' + NullDistributionName + "_" + totalIterations+'_burn'+burn+'_lag'+lag+'_chain'+chain+'.csv';

var posterior = Infer({
  model: model,
	method: "incrementalMH",
  samples: samples, burn: burn, lag: lag,
  verbose: T,
  verboseLag: totalIterations / 20,
	stream: {
		path: "results/" + outfile,
		header: ["type", "property", "param", "category", "val"]
	}
})

"written to " + outfile;
