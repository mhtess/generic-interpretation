\documentclass[floatsintext,man]{apa6}

\usepackage{amssymb,amsmath}
\usepackage{ifxetex,ifluatex}
\usepackage{fixltx2e} % provides \textsubscript
\ifnum 0\ifxetex 1\fi\ifluatex 1\fi=0 % if pdftex
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
\else % if luatex or xelatex
  \ifxetex
    \usepackage{mathspec}
    \usepackage{xltxtra,xunicode}
  \else
    \usepackage{fontspec}
  \fi
  \defaultfontfeatures{Mapping=tex-text,Scale=MatchLowercase}
  \newcommand{\euro}{€}
\fi
% use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
% use microtype if available
\IfFileExists{microtype.sty}{\usepackage{microtype}}{}

% Table formatting
\usepackage{longtable, booktabs}
\usepackage{lscape}
% \usepackage[counterclockwise]{rotating}   % Landscape page setup for large tables
\usepackage{multirow}		% Table styling
\usepackage{tabularx}		% Control Column width
\usepackage[flushleft]{threeparttable}	% Allows for three part tables with a specified notes section
\usepackage{threeparttablex}            % Lets threeparttable work with longtable

% Create new environments so endfloat can handle them
% \newenvironment{ltable}
%   {\begin{landscape}\begin{center}\begin{threeparttable}}
%   {\end{threeparttable}\end{center}\end{landscape}}

\newenvironment{lltable}
  {\begin{landscape}\begin{center}\begin{ThreePartTable}}
  {\end{ThreePartTable}\end{center}\end{landscape}}




% The following enables adjusting longtable caption width to table width
% Solution found at http://golatex.de/longtable-mit-caption-so-breit-wie-die-tabelle-t15767.html
\makeatletter
\newcommand\LastLTentrywidth{1em}
\newlength\longtablewidth
\setlength{\longtablewidth}{1in}
\newcommand\getlongtablewidth{%
 \begingroup
  \ifcsname LT@\roman{LT@tables}\endcsname
  \global\longtablewidth=0pt
  \renewcommand\LT@entry[2]{\global\advance\longtablewidth by ##2\relax\gdef\LastLTentrywidth{##2}}%
  \@nameuse{LT@\roman{LT@tables}}%
  \fi
\endgroup}


  \usepackage{graphicx}
  \makeatletter
  \def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
  \def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
  \makeatother
  % Scale images if necessary, so that they will not overflow the page
  % margins by default, and it is still possible to overwrite the defaults
  % using explicit options in \includegraphics[width, height, ...]{}
  \setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
\ifxetex
  \usepackage[setpagesize=false, % page size defined by xetex
              unicode=false, % unicode breaks when used with xetex
              xetex]{hyperref}
\else
  \usepackage[unicode=true]{hyperref}
\fi
\hypersetup{breaklinks=true,
            pdfauthor={},
            pdftitle={Generic statements have weak (and strong) implications},
            colorlinks=true,
            citecolor=blue,
            urlcolor=blue,
            linkcolor=black,
            pdfborder={0 0 0}}
\urlstyle{same}  % don't use monospace font for urls

\setlength{\parindent}{0pt}
%\setlength{\parskip}{0pt plus 0pt minus 0pt}

\setlength{\emergencystretch}{3em}  % prevent overfull lines


% Manuscript styling
\captionsetup{font=singlespacing,justification=justified}
\usepackage{csquotes}
\usepackage{upgreek}



\usepackage{tikz} % Variable definition to generate author note

% fix for \tightlist problem in pandoc 1.14
\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}

% Essential manuscript parts
  \title{Generic statements have weak (and strong) implications}

  \shorttitle{Context-sensitive generic interpretations}


  \author{Michael Henry Tessler\textsuperscript{1}~\& Noah D. Goodman\textsuperscript{1}}

  % \def\affdep{{"", ""}}%
  % \def\affcity{{"", ""}}%

  \affiliation{
    \vspace{0.5cm}
          \textsuperscript{1} Department of Psychology, Stanford University  }

  \authornote{
    This manuscript is currently in prep. Comments or suggestions should be
    directed to MH Tessler.
    
    Correspondence concerning this article should be addressed to Michael
    Henry Tessler, 450 Serra Mall, Bldg. 420, Rm. 316, Stanford, CA 94305.
    E-mail:
    \href{mailto:mhtessler@stanford.edu}{\nolinkurl{mhtessler@stanford.edu}}
  }


  \abstract{Enter abstract here. Each new line herein must be indented, like this
line.}
  \keywords{keywords \\

    \indent Word count: X
  }




  \usepackage{tabularx}
  \usepackage{multicol}
  \usepackage{wrapfig}
  \usepackage{caption}
  \usepackage{booktabs}
  \usepackage{amsmath}
  \usepackage{graphicx}
  \usepackage{subcaption}
  \usepackage{longtable}
  \usepackage{array}
  \usepackage{multirow}

\usepackage{amsthm}
\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{corollary}{Corollary}
\newtheorem{proposition}{Proposition}
\newtheorem{conjecture}{Conjecture}
\theoremstyle{definition}
\newtheorem{definition}{Definition}
\theoremstyle{definition}
\newtheorem{example}{Example}
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}
\theoremstyle{remark}
\newtheorem*{remark}{Remark}
\newtheorem*{solution}{Solution}
\begin{document}

\maketitle

\setcounter{secnumdepth}{0}



\newcommand{\denote}[1]{\mbox{ $[\![ #1 ]\!]$}}
\newcommand*\diff{\mathop{}\!\mathrm{d}}

\definecolor{Red}{RGB}{255,0,0} \definecolor{Green}{RGB}{10,200,100}
\definecolor{Blue}{RGB}{10,100,200}

\newcommand{\mht}[1]{{\textcolor{Blue}{[mht: #1]}}}
\newcommand{\ndg}[1]{{\textcolor{Green}{[ndg: #1]}}}
\newcommand{\red}[1]{{\textcolor{Red}{#1}}}







\section{Introduction}\label{introduction}

Learning from language is uniquely powerful because language can convey
information that difficult or dangerous to observe (e.g., learning that
certain plants are poisonous, staring at the sun causes blindness;
Gelman, 2009). The premier example of language's ability to transmit
abstract knowledge comes in the form of statements that convey
generalizations, otherwise known as \emph{generic language} (e.g.,
``Birds fly''; Carlson, 1977). One of the most important roles for
generic language is to provide learners with information about new or
poorly understood categories. As such, generics are ubiquitous in
everyday conversation and child-directed speech (Gelman, Coley,
Rosengren, Hartman, \& Pappas, 1998; Gelman, Goetz, Sarnecka, \& Flukes,
2008; Gelman, Taylor, Nguyen, Leaper, \& Bigler, 2004), and learning
from generics is thought to be central to conceptual development
(Cimpian \& Markman, 2009; Gelman, 2004). Understanding how beliefs are
updated from generic language is thus an important question for
cognitive science.

Abelson and Kanouse (1966) argued that generics, \enquote{\ldots{}once
accepted psychologically, {[}\ldots{}{]} appear to be commonly taken in
a rather strong sense, as though the qualifier \emph{always} had
implicitly crept into their interpretation} (p.~172). Gelman, Star, and
Flukes (2002) provided adults with generics about animals with
non-obvious properties (e.g., \enquote{Bears like to eat ants}) and
found that the \emph{implied prevalence} of the feature among category
members (e.g., the percentage of bears that like to eat ants) was high
(\(\sim 85\%\)). Similarly strong interpretations were reported using
novel categories with biological properties (e.g., ``Lorches have purple
feathers''; Cimpian, Brandone, \& Gelman, 2010, Expt. 1). The fact that
generics seem to convey strong implications may explain why social
stereotypes are propagted and maintained (Rhodes, Leslie, \& Tworek,
2012).

Do all generics carry strong implications? \enquote{Mosquitos carry
malaria} really seems to only have the quantificational force of an
existential claim, meaning \emph{some mosquitos carry malaria}. This may
not be a unique example: Cohen (2004) argues for a panolply of
conditions that give rise to \emph{existential generics} (e.g.,
focus-sensitive additives, as in \enquote{Birds lay eggs. Mammals lay
eggs too.}: the second sentence can be interpreted as true because of
the existence of platypuses and echidnas, both of which reproduce by
laying eggs). Using a similar implied prevalence task as Gelman et al.
(2002), Cimpian et al. (2010) (Expt. 3) found somewhat weaker
interpretations for features that could be construed as accidental
(e.g., ``Crullets have fungus-covered claws''; see also Khemlani,
Leslie, \& Glucksberg, 2009, 2012 for evidence for weak inferences from
generics). In these previous studies, the actual implied prevalence from
\enquote{weak} generics is still quite high (in Cimpian et al., 2010
Expt. 3, mean implied prevalence \(= 70\%\)), leaving open the question
of whether generics can receive genuinely weak interpretations (e.g.,
minority interpretations: \(< 50\%\)).

There are also open theoretical questions: property-specific generic
interpretations have been explained as theory-based expectations
(Cimpian, Gelman, \& Brandone, 2010; Leslie, 2008; Prasada, Khemlani,
Leslie, \& Glucksberg, 2013), but these notions have not been made
sufficiently precise to provide a quantative, predictive account of how
beliefs will be updated given a specific generic statement. Further, the
existence of context-sensitive interpretations has been used as evidence
against a quantitative account of generic language \emph{per se} and it
has been suggested that the normal tools of formal semantics are
inappropriate for studying generics (Leslie, 2008).
\mht{not sure if we want to take up the previous point to add to the contributions of this paper}
Tessler and Goodman (under review) proposed a quantitative model of
generic language as a kind of vague quantifier (or, uncertain threshold
model), combining tools from formal semantics and Bayesian modeling.
This model accounted for truth judgments or endorsements (e.g., is
\enquote{Mosquitos carry malaria} true or false?) about a wide range of
linguistic stimuli including generics about animals, habitual statements
about actions (e.g., \enquote{John runs}), and causal sentences (e.g.,
\enquote{This herb makes animals sleepy}). This endorsement model is
cast as a speaker deciding whether or not to assert a generic statement
to a listener, who will update her beliefs from the generic statement.
The listener model used therein provides a mapping from a generic
statement to implied prevalence---it is a quantitative account of how
generics update beliefs. This paper tests the predictions of this
listener model directly. In doing so, we also look for evidence for
\emph{weak generics}, which are predicted to exist and provide the
strongest test of the uncertain threshold account.

The paper is organized as follows. First, we review Tessler and Goodman
(under review)'s computational model of generic interpretation, describe
alternative models, and overview our experimental and data analytic
approach. In Expt. 1, we replicate and extend the findings of Cimpian et
al. (2010) that biological and accidental properties receive
differential interpretations. In Expt. 2, we extend these findings using
a larger and more diverse stimulus set better able to test the
quantitative predictions of our model and explore the existence of
\enquote{weak generics}. In Expt. 3, we experimentally manipulate the
background knowledge (the feature prevalence prior distribution) and
test its effect on interpretations of novel generics. In each
experiment, we compare the uncertain threshold model's predictions to
alternative models that have the same prior knowledge but which update
their beliefs via different semantic mechanisms (e.g.,
fixed-thresholds); in each case, we find the vague threshold model is
best able to account for context-sensitive generic interpretations.
Together, these results provide strong evidence that generics update
beliefs in a context-sensitive manner, well-modeled as a vague
quantifier.

\section{Computational model}\label{computational-model}

Generic language conveys generalizations about categories (Carlson,
1977; Leslie, 2008). Human generalization from observational data can be
well described using the language of probability (Shepard, 1987;
Tenenbaum, Kemp, Griffiths, \& Goodman, 2011), and so it makes sense
that probability would be at the core of the meaning of generalizations
conveyed in language. Tessler and Goodman (under review) formalize such
a hypothesis, positing that the semantics of generics are concerned with
probability but in an underspecified, context-dependent manner.

Using the truth-functional tools of formal semantics (Montague, 1973),
the literal meaning of a generic statement can be modeled as a threshold
function operating on the prevalence \(r\) of the feature in the
category (e.g., the proportion of mosquitos that carry malaria):
\(\denote{generic} = \{r > \theta\}\).\footnote{The prevalence \(r\) can
  be thought as a \enquote{prevalence in the mind}, or a subjective
  degree of belief about the property in the category, which may not
  accurately track the empirical frequency.} The literal meaning of
quantifiers can also be described by threshold functions (e.g.,
\(\denote{some} = \{r > 0\}\), \(\denote{most} = \{r > 0.5\}\),
\(\denote{all} = \{r = 1\}\)). Tessler and Goodman (under review) posit
that the corresponding threshold for the generic \(\theta\) is \emph{a
priori} uncertain---formally, is drawn from a context-invariant, uniform
prior distribution on thresholds \(P(\theta)\)---and is resolved by
context.\footnote{Of course, different threshold distributions could be
  learned over time for different properties. The choice of a uniform
  distribution here is to explore how well context-sensitive generic
  interpretations can be modeled by differences in corresponding prior
  beliefs about properties, without having to posit semantic differences
  between different generic sentences.}

In order for a statement to update beliefs about prevalence in a given
category, a listener must have prior beliefs about prevalence abstracted
across categories. To interpret a generic sentence, a listener draws
upon her abstract knowledge about properties, formalized by a prior
distribution over likely prevalence levels \(P(r)\).\footnote{Though not
  the direct focus of this work, the prevalence prior distribution can
  be seen as a relatively shallow formalization of theory-based
  expectations. Different theory-based relationships between kinds and
  properties will give rise to different prior distributions over
  prevalence. The prevalence prior, thus, acts as a statistical layer
  between conceptual knowledge and natural language semantics.} Thus the
quantitative model for generic interpretation is given by:

\begin{eqnarray}
L(r, \theta \mid u) &\propto& {\delta_{\denote{u}(r, \theta)} \cdot P(r) \cdot P(\theta)} \label{eq:L0}
\end{eqnarray}

Formally, the truth-functional meaning is represented by the Kronecker
delta function \(\delta_{\denote{u}(r, \theta)}\) that returns \(1\)
when the utterance is true (i.e., when \(r > \theta\)) and \(0\)
otherwise.

\begin{eqnarray}
\delta_{\denote{u_{gen}}(r, \theta)} &\propto  & \begin{cases}
1 & \text{if } r > \theta \\
0 & \text{otherwise}
\end{cases}\label{eq:delta}
\end{eqnarray}

The interpretation model computes a posterior distribution on prevalence
by considering different possible thresholds \(\theta\). Given a
particular value of \(\theta\), the literal semantics rules out all
prevalences \(r\) below \(\theta\). Consider the model behavior when the
prevalence prior is a uniform distribution
(\(P(r) = \text{Uniform}(0, 1)\)). Given a particular vlue of
\(\theta\), the posterior on prevalence will be uniform over all
prevalence levels above \(\theta\) (Figure~\ref{fig:modelSimulations}B;
top row); in addition, higher prevalence levels \(r\) are consistent
with more thresholds \(\theta\). Thus, given a uniform prevalence prior,
the generic interpretation model returns a non-uniform posterior that
favors higher prevalence levels (Figure~\ref{fig:modelSimulations}B; top
row, right-most column). This behavior captures the intuition that,
without strong background knowledge, generics probably imply that most
or all of the category has the property.

\subsection{The influence and structure of prevalence
priors}\label{the-influence-and-structure-of-prevalence-priors}

The generic interpretation model balances the prior probability of
different prevalence levels \(r\) with the overall preference for higher
prevalence levels (as described above), producing interpretations that
strongly depend on the prior distribution on prevalence \(P(r)\). The
prevalence prior for familiar properties may display interesting
structure reflecting domain-specific beliefs about the property.
Figure~\ref{fig:modelSimulations}A shows hypothetical prevalence priors
for the features \emph{fly} and \emph{carry malaria} as well as an
abstract property \emph{Y} without structured background knowledge.

The interpretation from the uncertain threshold model
(Figure~\ref{fig:modelSimulations}B, right-most column) is similar to
different quantified statements for different properties in question.
For the biological property prior, \enquote{Xs fly} is interpreted most
similarly to \enquote{Most Xs fly}. This results from the prior
distribution over a biological property like \emph{fly} being bimodal
with modes near 0\% and 100\%, reflecting the idea that for an arbitrary
category, it is likely that 0\% of them fly (e.g., dogs, rabbits,
etc\ldots{}); however, among categories with at least some members who
fly, we would expect all or nearly all of them to fly (hence, the second
mode near 100\%). For the accidental property prior, \enquote{Xs carry
malaria} is more similar to \enquote{Some Xs carry malaria} than
\enquote{Most Xs carry malaria}. Similar to the \emph{fly} prevalence
prior, the prior distribution over prevalence for a property like
\emph{carry malaria} has substantial probability mass at or near 0\%,
since most categories do not have the property present at all; however,
among categories with at least a few members who carry malaria, it is
very unlikely that all or even many carry malaria; the second mode of
this prior distribution is near 10\%.

In this way, the prevalence prior can be viewed as a distribution over
different categories (and their associated prevalence of the feature).
In a more abstract sense, this distribution can reflect causal beliefs
about kinds and properties (e.g., there is something internal or
external to the entity which causes it to have the property); if such a
causal mechanism is believed to exist for some kinds and not others, we
would expect the prevalence prior distribution to follow a mixture
distribution (e.g., a mixture of Beta distributions as is shown for the
\emph{fly}, \emph{lay eggs}, and \emph{carry malaria} cases
above).\footnote{This assumption is similar in spirit to that employed
  by \emph{Hurdle Models} of epidemiological data, where the observed
  count of zeros is often substantially greater than one would expect
  from standard models, such as the Poisson (e.g., when modeling adverse
  reactions to vaccines; Rose, Martin, Wannemuehler, \& Plikaytis, 2006)}
Such a structured prior distribution could vary by the mixture component
(e.g., for how many different kinds does the mechanism exist?) as well
as for the parameters of the component(s) that govern the prevalence for
the kinds with the mechanism (i.e., given that there is such a
mechanism, how strong do we expect that mechanism to be?). In Experiment
1, we assume this mixture-distribution structure to the prevalence prior
in order to measure beliefs about relatively obscure properties. In
Experiment 2, we measure the prevalence prior for more familiar
properties in a more direct, nonparametric way, and empirically verify
that the mixture of beta-distributions fits reasonably well. Finally, in
Experiment 3, we directly manipulate the prevalence prior.

\ndg{note: i changed "context" to other things (eg "property") in a bunch of places because what we're talking about is differences in target property and it's corresponding background knowledge. this is context in some sense, but i worry it would confuse people with more pragmatic / situated notions of context.}
\mht{wonder if we should make those changes more widespread (e.g., the running-head) or have an explicit statement about the kind of context we are considering here...}

\subsection{Alternative models and Bayesian data-analytic
strategy}\label{alternative-models-and-bayesian-data-analytic-strategy}

The uncertain threshold generic interpretation model presented here and
in Tessler and Goodman (under review) is the first cognitive model to
make quantitative predictions about human interpretations of generic
statements. In order to assess the predictive capabilities of this
model, we construct a number of alternatives for comparison. Foremost,
we compare the uncertain threshold model to a model of just the prior
distribution \(P(r)\). This comparison informs us as to whether or not
participants actually \emph{update} their beliefs based on the generic
statement. In addition, we construct two alternatives models by removing
the model's uncertainty about the threshold, corresponding to models of
quantifier interpretation. The first is a model of the quantifier
\enquote{some} which rules out the lowest possible prevalence level:

\begin{eqnarray}
L_{some}(r \mid u) &\propto&  P(r \mid r > 0)  \label{eq:someModel}
\end{eqnarray}

The second is analogous to \enquote{most}, with a threshold at 50\%
prevalence:

\begin{eqnarray}
L_{most}(r \mid u) &\propto&  P(r \mid r > 0.5)  \label{eq:mostModel}
\end{eqnarray}

A model that assumes a fixed threshold at 50\% is a very restricted
model; it places zero probability on any response less than 50\%. In
case there are ratings in the experimental data sets that are less than
50\%, we must supplement the \enquote{most} model with an extrinsic
noise process in order for this model to actually generate predictions
for those data; that is, with some probability, participants respond at
random. at random. We infer this noise probability parameter for the
\enquote{most} model from the data.

Our primary analyses ask how well the various interpretation models
accomodate the human generic interpretation data given our corresponding
measurements of the prevalence priors. To fit these models, we build
Bayesian data analysis (BDA) models to jointly predict the prevalence
prior data and the generic interpretation data. Such a joint-inference
model allows us to retain the uncertainty in the measurement of the
prevalence prior data when using it in our generics model to predict the
generic interpretation results.

\begin{figure}
\centering
\includegraphics{genint_files/figure-latex/modelSimulations-1.pdf}
\caption{\label{fig:modelSimulations}Model simulations. A: Prevalence priors
reflect knowledge about properties. An abstract property could be given
a uniform distribution, while familiar properties display more complex
structure. B: Posterior distributions over prevalence (interpretations)
given different fixed-threshold quantifiers and the uncertain threshold
generic.}
\end{figure}

\section{Experiment 1: Replication and extension of Cimpian et al.
(2010)}\label{experiment-1-replication-and-extension-of-cimpian-et-al.-2010}

Our model of generic interpretation (Eq. \ref{eq:L0}) predicts that the
interpretations of generics in terms of prevalence should vary as a
function of the prevalence prior. Cimpian et al. (2010) found a
difference in the implied prevalence between biological properties
(e.g., \emph{yellow fur}) and accidental properties (e.g.,
\emph{fungus-covered claws}). Classic work in generalization suggests
beliefs about the prevalence of properties include relatively fine
distinctions among properties that are all biological in nature
(Nisbett, Krantz, Jepson, \& Kunda, 1983). For this reason, we
elaborated the stimulus set from Cimpian et al. (2010) to include three
types of biological properties: body parts (e.g., \emph{fur}), body
parts of a particular color (e.g., \emph{yellow fur}) and body parts
described with a vague adjective (e.g., \emph{curly fur}). Here, we
empirically measure the prevalence priors for these properties using a
structured prior elicitation task (Expt. 1a) and use our interpretation
model to predict the prevalence implied by a generic statement about a
novel category (e.g., \enquote{Wugs have yellow fur}; Expt. 1b).

\subsection{Experiment 1a: Prior
elicitation}\label{experiment-1a-prior-elicitation}

This experiment measures the prevalence prior \(P(r)\) in Eq.
\ref{eq:L0} using a structured, prior elicitation procedure.

\subsubsection{Method}\label{method}

\paragraph{Participants}\label{participants}

We recruited 40 participants over Amazon's crowd-sourcing platform
Mechanical Turk (MTurk). We chose this number of participants based on
intuition from similar experiments which were designed primarily to test
a quantitative model. Participants were restricted to those with US IP
addresses and with at least a 95\% MTurk work approval rating. All
participants were native English speakers. The experiment took about 5-7
minutes and participants were compensated \$0.75.

\paragraph{Procedure and materials}\label{procedure-and-materials}

We constructed a stimulus set of forty different properties to explore a
wide range of \emph{a priori} beliefs about prevalence. These items make
up four categories of properties: body parts (e.g., \emph{fur}), body
parts of a particular color (e.g., \emph{yellow fur}), body parts
described with a vague adjective (e.g., \emph{curly fur}), and body
parts with in an accidental or disease state (e.g., \emph{wet fur}).
Because pilot testing revealed more variability for items in the
accidental category relative to the other types of properties, we used
twice as many exemplars of accidental properties, yielding a more
thorough test of the quantitative predictive power of the generic
interpretation model. We used eight exemplars of each of the three
non-accidental properties (parts, colored parts, vague parts), and
sixteen exemplars of accidental properties, building on a stimulus set
from Cimpian et al. (2010). List of properties is shown in Table 1 of
the Appendix.

Direct elicitation of background knowledge about the properties used in
Cimpian et al. (2010) (e.g., by asking about prevalence in familiar
categories) is difficult because many of the properties are fantastical
or obscure (e.g., pink teeth, silver legs, fungus-covered fur) leading
to a large component of the distribution at zero prevalence. Therefore,
we assume a mixture distribution structure and create an elicitation
task to measure two aspects of the prior: (1) the relative contribution
of zero-prevalence distribution (e.g., for how many categories is the
property expected to be present at all) and (2) the prevalence among
kinds where the property is present (\emph{prevalence when present}).

Participants were first introduced to a \enquote{data-collection robot}
that was tasked with learning about properties of animals. Participants
were told the robot randomly selected an animal from its memory to ask
the participant about (e.g., The robot says: \enquote{We recently
discovered animals called feps.}). To measure the relative contribution
of the zero-prevalence distribution, the robot asked how likely it was
that there \emph{was a fep with property} (e.g., \enquote{How likely is
it that there is a fep that has wings?}), to which participants reported
on a scale from \emph{unlikely} to \emph{likely}. To measure
\emph{prevalence when present}, the robot then asked the likely
prevalence assuming that at least one has the property (e.g.,
\enquote{Suppose there is a fep that has wings. What percentage of feps
do you think have wings?}). Participants completed a practice trial
using the property \emph{are female} to make sure they understood the
meanings of these two questions. For example, it is very likely that
there is a fep that is female because almost all animals have female
members (high \(P(\text{feature is present})\)). Additionally, when
present, the property is only expected in about 50\% of the category.

\subsubsection{Data analysis and
results}\label{data-analysis-and-results}

Question 1 elicits the mixture parameter of a 2-distribution mixture
model (\(P(\text{feature is present})\)). Question 2 elicits the
prevalence in a kind where the property is present. These elicited
parameters of the priors display a range of possible values
Figure~\ref{fig:cimpian-prevPrior}A. Biological properties are likely to
be present and when present, are likely to be widespread (top right
corner of scatter plot). More specific properties (either using gradable
adjectives or color adjectives) are expected to be slightly less
prevalent among the kinds where the property is present, perhaps
reflecting the fact that the same kind of animal can come in many
different colors or that gradable properties (e.g., \emph{big claws})
might not be ubiquitous in a category. Finally, accidental properties
are as likely to be present in a category as the color or gradable
properties (same \(P(\text{feature is present})\)), but are not expected
to be widespread even when present in the category (low \emph{prevalence
when present}).

From these two elicitation questions, we can reconstruct what the
prevalence priors should look like. We assume that kinds for which the
property is absent have prevalence levels sampled from a Beta
distribution that heavily favors numbers close to 0:
\(\text{Beta}(\gamma = 0.01; \xi = 100)\).\footnote{Note that we use the
  noncanonical mean \(\gamma\) and concentration \(\xi\) (or,
  inverse-variance) parameterization of the Beta distribution rather
  than the canonical shape (or pseudocount) parameterization for ease of
  posterior inference. The shape parameterization can be recovered
  using: \(\alpha = \gamma \cdot \xi; \beta = (1 - \gamma) \cdot \xi\).}
With that assumption, the prevalence distribution is given by:\footnote{All
  modeling results hold when this null distribution is assumed to be
  even more left-skewed \(\text{Beta}(\gamma = 0.001; \xi = 1000)\) or
  just a delta-function at zero \(\delta_{p=0}\).}

\begin{align}
\phi & \sim \text{Beta}(\gamma_1, \xi_1) \nonumber \\ 
r & \sim \begin{cases}
        \text{Beta}(\gamma_2, \xi_2) &\mbox{if } \text{Bernoulli}(\phi) = \textsc{T} \label{eq:priorModel}  \\
        \text{Beta}(\gamma = 0.01; \xi = 100) &\mbox{if } \text{Bernoulli}(\phi) = \textsc{F} \\
        \end{cases}
\end{align}

For data analysis, we assume participants' responses to both questions
(\(i \in \{\text{Question 1}, \text{Question 2}\}\)) are generated from
Beta distributions: \(d_{i} \sim \text{Beta}(\gamma_i, \xi_i)\), and put
uninformative priors over the parameters of each:
\(\gamma_i \sim \text{Uniform}(0, 1); \xi_i \sim \text{Uniform}(0, 100)\).
We implemented this Bayesian mixture-model in the probabilistic
programming language WebPPL (Goodman \& Stuhlmüller, 2014). To learn
about the credible values of the parameters of the model, we ran MCMC on
each item independently for 100,000 iterations, discarding the first
50,000 for burn-in.

Figure~\ref{fig:cimpian-prevPrior}B shows example reconstructed priors.
Biological properties (\emph{biological}, \emph{vague}, and \emph{color}
body parts) have prevalence distributions that are bimodal with peaks at
0\% and near-100\% prevalence, but differ in their variance around the
100\%-mode. By contrast, accidental properties do not have a substantial
second mode. This variability in prevalence priors leads the generic
interpretation model to predict different prevalence levels implied by
the generic.

\begin{figure}
\centering
\includegraphics{genint_files/figure-latex/cimpian-prevPrior-1.pdf}
\caption{\label{fig:cimpian-prevPrior}Prevalence priors for items from
Cimpian et al. (2010). A: Latent parameters governing prevalence priors
are different for different kinds of properties. B: The diversity in
parameters gives rise to different underlying distributions over
prevalence, which the generic interpretation model uses to make
predictions.}
\end{figure}

\subsection{Experiment 1b: Generic
interpretation}\label{experiment-1b-generic-interpretation}

This experiment measures the prevalence implied by a generic statement
about a novel category, which we then compare to the predictions of the
generic interpretation model \(L(p \mid u)\) (Eq. \ref{eq:L0}).

\subsubsection{Method}\label{method-1}

\paragraph{Participants}\label{participants-1}

We recruited 40 participants over MTurk. The experimental design is very
similar to Cimpian et al. (2010), and we chose to have a sample size at
least twice as large as the original study (original n=15). This is a
quantitative experiment with only quantitative comparisons planned. All
participants were native English speakers. The experiment took about 5
minutes and participants were compensated \$0.60.

\paragraph{Procedure and materials}\label{procedure-and-materials-1}

In order to get participants motivated to reason about novel kinds, they
were told they were the resident zoologist of a team of scientists on a
recently discovered island with many unknown animals; their task was to
provide their expert opinion on questions about these animals.
Participants were supplied with a generic about a novel category (e.g.,
\enquote{Feps have yellow fur.}) and asked to judge prevalence:
\enquote{What percentage of feps do you think have yellow fur?}
Participants completed in randomized order 25 trials: 5 for each of the
biological properties and 10 for the accidental. The experiment in full
can be viewed at
\url{http://stanford.edu/~mtessler/generics/experiments/asymmetry/asymmetry-2.html}.

\subsubsection{Results}\label{results}

Figure~\ref{fig:cimpian-modelingResults} shows the prevalence implied by
the forty novel generic sentences in the experiment. We find a gradient
of interpretation, mostly clustered by the type of property. We first
explore a qualitative trend predicted by the interpretation model,
before proceeding to a quantitative model analysis. Prevalence implied
by a generic is predicted to vary according to the prevalence prior,
which we can summarize by its mean. We ran a Bayesian mixed-effects beta
regression model with fixed-effects of intercept and slope (scaled prior
mean) with random by-participant effects of intercept and slope. There
is a clear positive relationship between the prevalence prior mean and
the implied prevalence (\(\beta_{\text{prev prior mean}}=\) 0.704
{[}0.508, 0.919{]}).

\subsection{Model-based analysis and
results}\label{model-based-analysis-and-results}

\begin{figure}
\centering
\includegraphics{genint_files/figure-latex/cimpian-modelingResults-1.pdf}
\caption{\label{fig:cimpian-modelingResults}Implied prevalence data and
model predictions for items from Cimpian et al. (2010). A: Mean implied
prevalence ratings for forty stimuli. B: Implied prevalence and generics
model prections collapsed across property type. C: Posterior predictive
model fits for quantitative models based on (i) the mean of the
prevalence prior, (ii) a threshold semantics fixed at 0.01
(\enquote{some}), (iii) a threshold semantics fixed at 0.5
(\enquote{most}), and (iv) an uncertain threshold semantics (generic).
Error bars denote bootstrapped 95\% confidence intervals for the
behavioral data and 95\% highest posterior density intervals for the
model predictions.}
\end{figure}

We now test the quantitative predictions of the model. We use the
prevalence priors reconstructed from Expt. 1a's structured elicitation
task via Eq. \ref{eq:priorModel} as the prevalence prior \(P(r)\) in Eq.
\ref{eq:L0} to predict the generic interpretation data. We built a
joint-inference Bayesian data analysis (BDA) model to predict both the
prevalence prior data and the generic interpretation data
simultaneously. We ran the model using 3 chains of MCMC for 750,000
iterations, the first 250,000 of which were discarded for burn-in.
Figure~\ref{fig:cimpian-modelingResults}B shows the generics model
predictions and the human data for each of the four types of properties
(collapsing across items within a property-type). We see that the model
displays the same sensitivity to the kind of property: Generics about
body parts are interpreted the strongest, accidental properties the
weakest, with the other two types falling in between.

We compare our generic interpretation to two lesioned versions of the
model, both of which lack the uncertain threshold (a \enquote{some} most
and a \enquote{most} model, described in the \textbf{Alternative models}
section above). Figure~\ref{fig:cimpian-modelingResults}C shows the
model predictions in the comparison to the behavioral data for each item
independently for the generics model, the two alternative fixed
threshold models, and the prevalence prior mean. The alternative models'
defects are apparent visually. The prevalence prior, though it is highly
correlated with the posterior (\(r^2(40)=\) 0.751), predicts too low
values, resulting in a high mean squared error (\(MSE=\) 0.151). The
\enquote{some} model is similar: It is highly correlated (\(r^2(40)=\)
0.855) but underpredicts the data (\(MSE=\) 0.0349). The \enquote{most}
+ noise model achieves a pretty good fit to the data (\(r^2(40) =\)
0.847; \(MSE=\) 0.0129), but only does so because it predicts about a
third of the data set is noise (proportion noise =
\(0.37 (0.33, 0.42)\)). Finally, the uncertain threshold generic
interpretation model explains practically all of the variance in the
data (\(r^2(40) =\) 0.953) and achieves an extremely low mean squared
error (\(MSE =\) 0.00229).

\subsection{Discussion}\label{discussion}

We replicated Cimpian et al. (2010)'s finding of a difference in the
implied prevalence between biological properties (e.g., \emph{yellow
fur}) and accidental properties (e.g., \emph{fungus-covered claws}). We
extended these findings with a broader stimulus set and discovered even
more gradability in interpretations of generic statements. We
empirically measured the prevalence priors and used our generic
interpretation model to predict prevalence implied by a generic
statement.

\mht{does this add anything? do we want to speculate a little more about where these differences in parameters might come from?}
The structured elicitation of prevalence knowledge in Expt. 1a provides
a more detailed picture of what differs between these kinds of
properties. Properties differ in both the \emph{a priori} probability of
being present in a category as well as how widespread the property would
be expected to be, given that it is present
(Figure~\ref{fig:cimpian-prevPrior}). It is these differences that give
rise to different implied prevalence ratings for generics about
different properties.

The items that receive the lowest implied prevalence are those of
accidental or diseased states (e.g., \emph{fungus-covered claws},
\emph{broken legs}). As Cimpian et al. (2010) noted, \enquote{properties
of this type do not lend themselves very well to generic predication
(Cimpian \& Markman, 2008; Gelman, 1988), so generics about broken legs,
itchy skin, etc. are infrequent outside the laboratory.} (p.1472) It,
thus, remains a possibility that participants treat statements such as
\enquote{Lorches have broken legs} as an existential claim about the
here-and-now, analagous to how \enquote{Dogs are on my front lawn}
describes a particular state of affairs as opposed to something
generalizable about dogs. We thus aim to replicate these findings of low
prevalence prevalence interpretations in the next experiment, using
properties that more naturally lend themselves to generic
interpretation. In addition, we use more naturalistic properties and
measure background knowledge using a more direct elicitation technique
that does not presuppose a structured model for the prevalence prior.

\section{Experiment 2}\label{experiment-2}

This experiment is designed to measure the prevalence implied by a
generic about a diverse set of properties (Expt. 2b). In addition, we
elicit participants' beliefs about the likely prevalence levels expected
for these different properties (Expt. 2a). We again use our
computational model and alternative models, all using the elicited
prevalence priors, to make predictions about the prevalence implied by a
generic.

\subsection{Experiment 2a: Prevalence prior
elicitation}\label{experiment-2a-prevalence-prior-elicitation}

In this experiment, we elicit prevalence knowledge about a diverse set
of familiar properties. Because the properties are relatively familiar,
we elicit participants' knowledge without assuming a particular
structure (as was done in Expt. 1a). This allows us for a non-parametric
examination of the priors.

\subsubsection{Methods}\label{methods}

\paragraph{Participants}\label{participants-2}

We recruited 200 participants from MTurk. This number was arrived at
with the intention of getting approximately 23 independent sets of
ratings for each unique item in the experiment. Participants were
restricted to those with U.S. IP addresses and with at least a 95\%
MTurk work approval rating (these same criteria apply to all experiments
reported). The experiment took on average 7.40 minutes and participants
were compensated \$0.80.

\paragraph{Materials}\label{materials}

We created a stimulus set composed of seventy-five properties. Items
were generated by the first author by considering eight different
classes of properties: physical characteristics (e.g., \emph{have brown
spots}, \emph{have four legs}), psychological characteristics (e.g.,
\emph{experience emotions}), dietary habits (e.g., \emph{eat human
food}), habitat (e.g., \emph{live in zoos}), disease (e.g., \emph{get
cancer}, \emph{carry malaria}), reproductive behavior (e.g., \emph{have
a menstrual cycle}), aggressive behaviors (e.g., \emph{pound their
chests to display dominance}, \emph{hunt other animals}), and other
miscellaneous behaviors (e.g., \emph{perform in the circus}, \emph{sing
beautiful songs}); online sources about strange animal behaviors were
consulted in order to find the more obscure properties. Full list of
materials can be found in \red{Table X} in Appendix.

\paragraph{Procedure and materials}\label{procedure-and-materials-2}

On the first trial, participants were asked to list three kinds of
animals for each of five different classes of animals: mammals, fish,
birds, insects/bugs, amphibeans/reptiles. The five classes of animals
were presented in a randomized order on the screen and there were three
text boxes for each in which participants could type an animal kind. On
subsequent trials, participants were shown a random subset of five
animal kinds and asked what percentage each of these categories they
believed had a property (e.g., \enquote{Out of all of the cheetas in the
world, what percentage do you think attack hikers?}). Pilot results
indicated similar responses were generated by a question about frequency
(e.g., \enquote{Out of 100 cheetahs, how many do you think attack
hikers?}). Participants responded using a slider bar with endpoints
labeled 0\% and 100\%, and the exact number corresponding to their
slider bar rating was displayed once participants clicked on the slider
bar. Each participant saw a random selection of twelve properties.

\ndg{say something about why elicitation paradigm is different for this expt than last one? partly to give a non-parametric look at priors?}
\mht{i did this in the introductory remarks about the expt.}

As an attention check, at the end of the prior elicitation trials,
participants were asked to select, from a list of ten, all of the
properties they could remember being tested on. The list included five
properties that they had been tested on and five distractors. The
experimental paradigm can be seen here:
\url{http://stanford.edu/~mtessler/generic-interpretation/experiments/generics/prior-3.html}.

\subsubsection{Results}\label{results-1}

We used the same exclusion criteria that were preregistered for the
subsequent generic interpretation study (Expt. 2b):
\url{https://osf.io/bwn4t/register/5771ca429ad5a1020de2872e}.
Participants who did not have at least 4 out of 5 hits and at least 4
out of 5 correct rejections during the memory trial were excluded
(\(n = 15\)). In addition, we excluded participants who self-reported a
native language other than English (\(n = 13\)). This left a total of
\(n = 175\) participants, with items receiving on average 28 (range =
{[}16, 38{]}) unique participants responses (each participant provides
five ratings).

A response in this task can be thought of as a sample from a property's
prevalence prior distribution. Thus, the distribution of responses for
an item are an estimate of the prevalence prior distribution.
Figure~\ref{fig:genInt-prevPrior}A shows eight example items'
distributions of responses. For example, the property \emph{have four
legs} is most likely either completely present (prevalence = 100\%) or
completely absent (prevalence = 0\%) from categories. \emph{Eat insects}
looks similar, though there is considerable probability mass spread
among the non-binary alternatives (\(0\% <\) prevalence \(< 100\%\)).
\emph{Get in fights with other animals} is similar but has substantially
less probability mass at 100\% prevalence: It is unlikely that this
property is widespread in a category. \emph{Live in urban areas} shows a
monotonically decreasing probability function; the higher the
prevalence, the less likely it is. \emph{Live in zoos} is expected to be
even less prevalent, and the property \emph{has seizures} is expected to
not be widespread at all. The property \emph{get erections} is only
expected to be present in 50\% of the population (presumably, the males)
when it is present at all.

Most of the elicited prevalence prior distributions are at least
bi-modal. To visualize all properties simultaneously, we represent each
distribution by its relative probability mass at
0\%---\(P(\text{feature is present})\), or \(P(r > 0)\)---and the
expected value (mean) of the distribution conditional on the prevalence
being greater than 0\%---\(\mathbb{E}[P(r \mid r>0)]\) or the its
\emph{prevalence when present} (Figure~\ref{fig:genInt-prevPrior}B). Our
stimulus set covers a wide range of possible values of both of these
parameters; the set of parameters that summarize these priors is also
largely non-overlapping with those of Expt. 1 (compare with
Figure~\ref{fig:cimpian-prevPrior}A). This suggests we have sampled
items with priors that exhibit a lot of quantitative variability. Given
these priors, our model makes quantitative predictions about the
prevalence implied by a novel generic sentence (e.g., \enquote{Lorches
live in zoos}).

\begin{figure}
\centering
\includegraphics{genint_files/figure-latex/genInt-prevPrior-1.pdf}
\caption{\label{fig:genInt-prevPrior}Prevalence priors for a broad set of
animal properties. A: Ten example prevalence priors elicited in Expt.
2a. Different prevalence priors give rise to different model predicted
implied prevalence. B: Prevalence priors summarized by their relative
probability mass at zero-prevalence P(feature is present), and their
expected value among non-zero prevalence levels: Prevalence when
present. Error bars denote bootstrapped 95\% confidence intervals.}
\end{figure}

\subsection{Experiment 2b: Generic
interpretation}\label{experiment-2b-generic-interpretation}

\subsubsection{Methods}\label{methods-1}

\paragraph{Participants}\label{participants-3}

We recruited 200 participants from MTurk. This number was arrived at
with the intention of getting approximately 50 ratings for each unique
item in the experiment. The experiment took on average 5.50 minutes and
participants were compensated \$0.80.

\paragraph{Procedure and materials}\label{procedure-and-materials-3}

The materials were the same as in Expt. 2a. Participants were told that
scientists had recently discovered lots of new animals that we did not
know existed. On each trial, they would be told facts about the new
animals and be asked to translate it into the percentage of that animal
it applies to. On each trial, participants read \enquote{You are told:
\emph{generic sentence}}, where the generic sentence was a bare plural
statement about a familiar property \(F\) applying to a novel animal
category \(K\) (e.g., \enquote{Javs attack hikers}). They were then
asked \enquote{Out of all of the \emph{K}s on the planet, what
percentage do you think \emph{F}?} (e.g., \enquote{Out of all of the
javs on the planet, what percentage do you think attack hikers?}). Novel
animal category names were mostly taken from Cimpian et al. (2010) and
similar studies on generic language. Participants responded using a
slider bar with endpoints labeled 0\% and 100\%, and the exact number
corresponding to their slider bar rating was displayed once participants
clicked on the slider bar. Each participant completed thirty-five
trials, corresponding to a random subset of the full stimulus set.

After the generic interpretation trials, participants completed the same
memory check trial as was done in the prior elicitation. They were shown
ten properties and asked to click on those they had seen in the
experiment. Following the memory check trials, participants completed up
to five explanation trials, depending on their ratings in the task. On
an explanation trial, participants saw a rating they had given for a
property they had rated as applying to less than 50\% and asked if they
could explain why they gave the response that they gave. Participants
also had the option of changing their response after providing an
explanation. These data were only used in exploratory analyses and not
for the main analysis reported below. If participants gave no ratings
less than 50\%, they did not complete any explanation trials.

The experimental paradigm can be viewed at
\url{http://stanford.edu/~mtessler/generic-interpretation/experiments/generics/interpretations-6.html}

\subsubsection{Results}\label{results-2}

We used preregistered exclusion criteria, which were also used for Expt.
2a. Participants who did not have at least 4 out of 5 hits and at least
4 out of 5 correct rejections during the memory trial were excluded
(\(n = 62\)). In addition, we excluded participants who self-reported a
native language other than English (\(n = 8\)). This left a total of
\(n = 132\) participants, with items receiving on average 62 responses
(range = {[}50, 77{]}).

\paragraph{Descriptive results}\label{descriptive-results}

Interpreting a novel generic sentence \enquote{Ks have F} often has the
possibility of being understood as a universal or near-universal claim
(\emph{all or almost all Ks Fs)}. Across our seventy-five items,
however, we observe a clear gradient in the implied prevalence ratings
(Figure~\ref{fig:genint-modelingResults}A). On one end of the continuum,
there is a generic like \enquote{Wugs have four legs}, which is
interpreted as a universal---applying to exactly 100\% of wugs---by 36
out of 70 participants and which received a mean implied prevalence
rating of \(0.96 [0.93, 0.98]\).\footnote{Note the novel category term
  is randomized for each participant and property. We use particular
  novel category terms in the text for ease of exposition.} On the other
end is \enquote{Glippets perform in the circus}, which is interpreted as
applying to less than 25\% of glippets by 35 out of 61 participants and
which receives a mean rating below 50\% (\(0.31 [0.23, 0.39]\)).
Additionally remarkable is the distribution of responses for individual
items: Though \enquote{Feps live in zoos} probably means around 25\% of
feps live in zoos, it is still quite possible that almost 100\% live in
zoos (e.g., in the real world, 100\% of Micronesian Kingfishers live in
zoos).

To assess the reliability of these data, we ran a replication
(\(n=140\)) using a slightly different dependent measure.\footnote{By
  experimenter error, only seventy-four of the seventy-five items were
  collected in the replication data set.} Instead of being asked a
question about percentages (e.g., \enquote{Out of all of the Ks in the
world, what percentage F?}), participants were asked a question in terms
of frequency: \enquote{Out of 100 Ks, how many do you think F?}. The
empirical by-item means between these data and the original data are
highly correlated (\(r(74) = 0.96\), \(r_{spearman}(74)= 0.96\)),
indicating very high data reliability.

\paragraph{Model-based analysis and
results}\label{model-based-analysis-and-results-1}

Our primary analysis concerns how well the uncertain threshold generic
interpretation model can accomodate the implied prevalence data in
comparison to alternative models. To fit these models, we follow the
same Bayesian data analytic approach as Expt. 1 to jointly predict the
prevalence prior data (Expt. 2a) and the generic interpretation data
(Expt. 2b). We model the prevalence prior data as a mixture of three
Beta distributions. Each prevalence prior, thus, has eight parameters
governing its shape: a mean \(\gamma\) and variance parameter \(\xi\)
for each of the three Beta components and two parameters \(\phi_1\),
\(\phi_2\) that describe the relative weighting among the three
components. We put uninformative priors over these parameters
\(\gamma \sim \text{Uniform}(0, 1)\),
\(\xi \sim \text{Uniform}(0, 100)\),
\(\phi \sim \text{Dirichlet}(1,1,1)\). The inferred prevalence prior
distributions are then used as \(P(r)\) in Eq. \ref{eq:L0} in order to
generate predictions for the generic interpretation data.\footnote{In
  reality, this procedure is done simultaneously, not sequentially.} The
generic interpretation model is fully specified by Eq. \ref{eq:L0} and
has no free parameters.

To learn about the credible values of the parameters governing the
prevalence priors as well as generate model predictions for the generic
interpretation data, we performed Bayesian inference on the model by
running three chains of an incrementalized version of MCMC (Ritchie,
Stuhlmüller, \& Goodman, 2016) for 750,000 iterations, removing the
first 250,000 iterations for burn-in. A qualitative examination showed
that the prevalence prior distributions were well-modeled as a mixture
of three Beta distributions. Often one Beta distribution is devoted to
accounting for the very small numbers (0\% or near 0\% prevalence
ratings), while the two other components model the other parts of the
distribution, the details of which depend upon the property. To provide
a quantitative examination of the fit to the priors data, we look at the
posterior predictive distribution discretized to bins in increments of
10\% prevalence (i.e., categorical distributions over the bins of 0\%,
10\%, \ldots{}, 90\%, 100\% prevalence) and compare the model's inferred
priors to the empirical counts that fell into those bins. The joint data
analysis model accomodates the empirical patterns in the prevalence
priors very well: \(r^2(825) = 0.99\), \(MSE = 0.00052\).
\ndg{we should have a brief result reporting the posterior predictive check on the priors data? ie how well does our joint data analysis accommodate the empirical patterns in the prevalence priors.}
\mht{above. okay?}

As a first attempt to understand the implied prevalence data in a
quantitative way, we compare the means of the inferred prevalence priors
to the empirical means of the implied prevalence data
(Figure~\ref{fig:genint-modelingResults}B top facet). The means of the
prevalence prior distributions do a rather poor job at predicting the
implied prevalence ratings, consistently underpredicting the ratings
(\(r^2(75) = 0.59\), \(MSE = 0.24\)). The fact that the prevalence prior
data underpredicts the generic interpretation data is good evidence that
participants are actually \emph{updating} their beliefs about the
property in the generic interpretation task, as opposed to simply
responding according to their prior beliefs.

As before, we ran alternative interpretation models using the same data
analytic approach (i.e., joint cognitive-statistical models) but which
had access to only a single fixed-threshold rather the uncertain
threshold of the generic interpretation model.
Figure~\ref{fig:genint-modelingResults}B shows each of the alternative
model's predictions (technically, the BDA models' posterior predictive
distributions) for the mean implied prevalence of each of the
seventy-five novel generic sentences, in comparison to the empirical
means. We see that the model based on quantifier \enquote{some} (i.e., a
fixed threshold at the lowest possible value) consistently
\emph{underpredicts} the implied prevalence, consistent with the
intuition that assigning the semantics of \enquote{some} for generics is
too weak. Though the model explains a lot of the variance
\(r^2(75) = 0.91\), it does so with a relatively high mean squared error
\(MSE = 0.038\). The \enquote{most} model assigns 0.57 {[}0.55, 0.59{]}
proportion of the data to be noise, because of the high prevalence of
minority (i.e., less than 50\%) interpretations. A model based on the
semantics for \enquote{most} is also not well-suited for these data
\(r^2(75) = 0.49\), \(MSE = 0.021\).

Finally, we examine the uncertain threshold model's predictions for the
mean implied prevalence ratings. Unlike each of the alternative models,
the uncertain threshold is able to perfectly accomodate the highly
variable generic interpretation data \(r^2(75) = 0.97\),
\(MSE = 0.0025\). The generic interpretation model is able to flexibly
adjust the threshold depending on the prevalence prior, resulting in
context-sensitive generic interpretation that finely tracks human
judgments.

\begin{figure}
\centering
\includegraphics{genint_files/figure-latex/genint-modelingResults-1.pdf}
\caption{\label{fig:genint-modelingResults}Implied prevalence data and model
predictions for a broad set of seventy-four items. A: Mean implied
prevalence ratings (points are individual empirical judgments). B:
Posterior predictive model fits for quantitative models based on (i) the
mean of the prevalence prior, (ii) a threshold semantics fixed at 0.01
(\enquote{some}), (iii) a threshold semantics fixed at 0.5
(\enquote{most}), and (iv) an uncertain threshold semantics (generic).
The model for \enquote{most} is outfitted with a noise parameter to
accomodate data points that are logically impossible given the fixed
semantics. Error bars denote bootstrapped 95\% confidence intervals for
the behavioral data and 95\% highest posterior density intervals for the
model predictions.}
\end{figure}

\subsection{Discussion}\label{discussion-1}

In Expt. 2, we extended the findings of Expt. 1 to a larger and more
diverse set of stimuli. We uncovered a continuum of interpretations of
novel generic statements, and were able to predict the gradience in
interpretation using the uncertain threshold generics model. Graded
interpretations of generic statements result from diverse prior beliefs
about properties operated over using an underspecified threshold
criterion. In our final experiment, we experimentally manipulate these
prior beliefs to test their causal role in governing generic
interpretations.

\section{Experiment 3: Prior
Manipulation}\label{experiment-3-prior-manipulation}

In the previous experiments, we saw how participants' prior beliefs
about the prevalence of the property, either measured by asking about
alternative categories (Expt. 2) or abstract questions about the
distribution of the property (Expt. 1), related to the prevalence
implied by a novel generic via a model that reasons about an uncertain
threshold on prevalence (Eq. \ref{eq:L0}). In both of the previous
experiments, we measured both generic interpretation and the prevalence
prior and related the two via the uncertain threshold model. Though our
model is able to finely track interpretations in a way that alternative
models cannot, the evidence so far for the influence of the prevalence
prior on interpretation is merely correlational. We have shown that the
two are related but not that intervening on the prevalence prior can
change interpretations.

In this final experiment, we test the causal role of the prevalence
prior in generic interpretation. We do this by manipulating the
prevalence prior and measuring the resulting influence on interpretation
(\emph{generic interpretation} condition). To serve as a manipulation
check, we first elicit predictions about prevalences following our prior
manipulation procedure; these predictions also serve as the measurements
of the (manipulated) prevalence priors used in our model.

\subsection{Experiment 3a: Prior elicitation (manipulation
check)}\label{experiment-3a-prior-elicitation-manipulation-check}

\subsubsection{Methods}\label{methods-2}

\paragraph{Participants}\label{participants-4}

We recruited 200 participants from MTurk. This number was arrived at
with the intention of getting approximately 30 ratings for each unique
item in the experiment. The experiment took on average 3 minutes and
participants were compensated \$0.30.

\paragraph{Materials}\label{materials-1}

The goal of this experiment was to manipulate the prevalence prior. To
focus on the influence of our prior manipulation cover story (described
below), we chose to use a single property (\emph{know when earthquakes
are about to happen}) whose prevalence prior elicited in Expt. 2a
suggested participants had a lot of uncertainty as to what prevalence
levels to expect for this property, and thus could be particularly
amenable to manipulation.\footnote{Pilot testing using a completely
  novel property (e.g., \emph{daxing}) appeared to make the task too
  artificial. Participants seemed to treat the task as a number game.}

Participants were familiarized with one of ten prevalence prior
distributions, shown in Figure~\ref{fig:priorManipulationExpt}E). Nine
of the ten distributions are bimodal with modes either at 0\%, 25\%,
50\%, 75\%, or 100\%; the tenth distribution is uniform over all
prevalence levels between 0\% and 100\%. The mixture between the two
modes was always 50\% (half of samples were from one mode and half from
the other, as shown in Figure~\ref{fig:priorManipulationExpt}B).

\paragraph{Procedure}\label{procedure}

\begin{figure}
\centering
\includegraphics{genint_files/figure-latex/priorManipulationExpt-1.pdf}
\caption{\label{fig:priorManipulationExpt}Overview of Experiment 3. A:
Prevalences of feature in animals are shown one at a time, described in
text and displayed in a table. B: Participants are asked to review
previous results once all displayed. C: Prior elicitation task:
Participants predict the results of the next five animals. D: Generic
interpretation task: Participants rate prevalence after reading generic
sentence. E: Experimentally manipulated prevalence prior distributions.
The distribution shown in B is the \emph{weak or deterministic}
distribution.}
\end{figure}

In order to avoid participants learning the structure of the task,
participants completed only a single trial: Each participant saw only
one prevalence distribution. Participants were given a cover story in
which they were asked to imagine they were an astronaut-scientist
exploring a distant planet with lots of new animals on it. They were
studying these animals with another scientist to understand the animals'
ability to \enquote{know when earthquakes are about to happen}.
Participants were then shown data that they and their fellow scientist
had collected about the prevalence of the property among different novel
animals. In order to minimize distraction, novel animals were simply
labeled by a letter (e.g., \enquote{Animal C} or just \enquote{Cs}).
Information about the animal appeared in an \emph{evidence statement}
(e.g., \enquote{After studying the animal, you and your partner
determine that 98\% of Cs \emph{know when earthquakes are about to
happen}.}) and were displayed in a table showing the corresponding
numerical data (Figure~\ref{fig:priorManipulationExpt}A). Participants
proceed in a self-paced way by clicking a button to reveal information
about the next animals. After participants viewed the data for ten
categories, they are told to review the information about the animals
before continuing (Figure~\ref{fig:priorManipulationExpt}B). Then, the
data table is removed and participants are provided the following
prompt:

\begin{quote}
Tomorrow, you and your partner will study 5 other new species of
animals. What percentage of each do you think will know when earthquakes
are about to happen?
\end{quote}

Participants were given five slider bars ranging from 0\% - 100\%, and
asked to predict the prevalence for the next five categories (Animals K
- P; Figure~\ref{fig:priorManipulationExpt}C). After rating the slider
bars, participants were asked if they could explain why they gave the
responses that they did. Then, they completed an attention check survey
where they were asked what property was being investigated (choosing a
response from a list of 10 options) and to input one of the prevalence
levels they saw on the familiarization screen.

\subsubsection{Results}\label{results-3}

Participants who failed to either select the correct property or list a
correct number from the familiarization period were excluded.

Similar to the data from Expt. 2a, a response in this task can be
thought of as a sample from a prevalence prior distribution and the
distribution of responses as estimates for the whole distribution. We
visualize the distributions by discretizing the responses so that each
response goes into one of twenty equally spaced bins (effectively
turning the 101-pt scale into a 20-pt scale).
Figure~\ref{fig:priorManipulationResults}A (top row) shows the
empirically elicited predicted prevalence distributions. These
distributions clearly reflect the familiarization distributions supplied
to participants in the experiment, with some idiosyncractic features.
The distribution that is most different from the familiarization
distribution is the uniform distribution; the empirical predicted
distribution is more unimodal with a peak at 50\%. Many distributions
exhibit a regression to the mean in some participants' predictions: In
the \emph{rare or deterministic} distribution (which featured prevalence
levels either around 0\% or 100\%), some participants guess that the
next animal will have 50\% prevalence; a similar phenomenon can be
observed in the \emph{weak or strong} distribution (25\% or 75\%) and to
a lesser extent in the other bimodal distributions.

Because our generic interpretation model has no free parameters, we use
these empirically measured prevalence distributions to generate \emph{a
priori} model predictions using the generic interpretation data. To
account for our uncertainty in the measurement of the prevalence priors,
we bootstrap the priors by resampling subjects (with replacement),
calculating the empirical prevalence distributions (by binning, as
above), and generating model predictions. We repeated this procedure
10,000 times to generate distributions of predictions. The boostrapped
mean and 95\% quantiles for each prevalence bin in each distribution are
shown in Figure~\ref{fig:priorManipulationResults}A (middle row). We see
that context-sensitive interpretations are predicted, with
idiosyncracies that reflect empirically measured distributions. We then
tested these predictions against interpretations in the same empirical
paradigm.

\begin{figure}
\centering
\includegraphics{genint_files/figure-latex/priorManipulationResults-1.pdf}
\caption{\label{fig:priorManipulationResults}Experiment 3 results. A:
Empirical distribution of responses for the prior elicitation task
(Expt. 3a), generics model predictions based on those empirical
distributions, and empirical distributions of responses for the generic
interpretation task (Expt. 3b). B: Model predicted means for several
alternative models and empirical means. C: Same as B shown in
scatterplot.}
\end{figure}

\subsection{Experiment 3b: Generic
interpretation}\label{experiment-3b-generic-interpretation}

\subsubsection{Methods}\label{methods-3}

The sample size, exclusion criteria, and planned statistical contrasts
were all preregistered:
\url{https://osf.io/n342q/register/5771ca429ad5a1020de2872e}.

\paragraph{Participants}\label{participants-5}

We recruited 600 participants from MTurk. This number was arrived at
with the intention of getting approximately 50 ratings for each unique
item in the experiment. The experiment took on average 2.70 minutes and
participants were compensated \$0.30.

\paragraph{Materials and procedure}\label{materials-and-procedure}

The materials and procedure were identical to those of Expt. 3a with the
following exception. After the familiarization period, the data table is
removed and participants are provided the following prompt:

\begin{quote}
The next day, you are busy and your partner studies a new animal on
their own: Animal K. Your partner tells you: \enquote{Ks know when
earthquakes are about to happen.}
\end{quote}

In order to encourage participants to pay attention to the language,
this text is on the screen for five seconds before participants are
asked: \enquote{What percentage of Ks do you think know when earthquakes
are about to happen?} and provided with a slider bar ranging from
0\%-100\% (Figure~\ref{fig:priorManipulationExpt}D). As in Expt. 3a,
participants then completed an attention check survey where they were
asked what property was being investigated and to input one of the
prevalence levels they saw on the familiarization screen. The experiment
can be viewed at
\url{http://stanford.edu/~mtessler/generic-interpretation/experiments/generics/prior-manipulation-2.html}.

\subsubsection{Results}\label{results-4}

We used preregistered exclusion criteria, which were also used for Expt.
3a. Participants who failed to either select the correct property or
list a correct number from the familiarization period were excluded
(\(n = 39\)). In addition, we excluded participants who self-reported a
native language other than English (\(n = 33\)). This left a total of
\(n = 532\) participants, with items receiving on average 53 responses
(range = {[}43, 62{]}).

Our main qualitative hypothesis is that there would be a difference
across conditions in interpretations of the same generic sentence
(\enquote{Ks know when earthquakes are about to happen}). The
differences in interpretations are evident in the empirical
distributions of responses (Figure \ref{fig:priorManipulationResults}A,
bottom row). More specifically, we predict that the prevalence implied
by the generic sentence will, to a first approximation, track the mean
of the prevalence prior distribution. To test this, we ran a linear
model predicting responses with a fixed effect of the prior mean (as
estimated by the data from Expt. 3a). There was a significant main
effect of prior mean, with a coefficient close to 1 (\(\beta_1 = 0.94\),
\(SE=0.07\), \(t = 12.76\)), indicating a strong linear relationship
between the mean of the learned prevalence prior and the resulting
interpretations. Furthermore, there was a significant main effect of
intercept, indicating that participants' responses were significantly
greater than the mean of the corresponding prevalence priors
(\(\beta_0 = 0.16\), \(SE=0.04\), \(t = 4.44\)). These results show that
participants interpret the novel generic sentence in a manner sensitive
to the background distribution and that the generic utterance updates
participants' beliefs to indicate a prevalence significantly higher than
the prior. There is a lot more to be learned from these data, however;
this simple linear model explains less than a quarter of the variance in
the data \(r^2 = 0.24\).

From the generics model, we are able to make a number of \emph{a priori}
predictions about quantitative differences in mean implied prevalence
ratings across the ten conditions. These predictions were derived by
examining pairs of conditions with small quantitative differences but
for which the bootstrapped 95\% confidence interval around the generics
model predictions did not overlap
(Figure~\ref{fig:priorManipulationResults}B, \enquote{generics model}
panel). With those criteria in mind, we preregistered the following
contrast predictions among mean implied prevalences (\{\}s indicate no
predicted difference): 0/25 \(<\) \{25/50, 0/50\} \(<\) \{25/75,
\emph{uniform}\} \(<\) 25/75 \(<\) \{25/100, 50/100\} \(<\) \{75/100,
0/100\}. To evaluate these predictions, we built a Bayesian regression
model with the relevant contrasts using a \enquote{zero and one inflated
beta} linking function to appropriately model the responses of exactly
0\% and 100\%, which are undefined under the beta distribution. The
maximum a-posteriori estimates and 95\% credible intervals of the
coefficients of the regression model, as well as the model predicted
qualitative differences, are shown in Table 1. Each of the five
predicted positive differences were estimated to be greater than zero,
and each of the four predicted null differences were not different from
zero. Overall, the uncertain threshold model predicts much of the
variance in the means of these empirical distributions:
\(r^2(10) = 0.89; MSE = 0.00427\)

\begin{table}[H]
\centering
\begingroup\fontsize{9pt}{10pt}\selectfont
\begin{tabular}{llrl}
  \hline
coefficient & prediction & Estimate & credible\_interval \\ 
  \hline
Intercept &  & 0.32 & [ 0.221, 0.418] \\ 
  0/25 vs. \{25/50, 0/50\} & $>$ & 0.15 & [ 0.036, 0.278] \\ 
  25/50 vs. 0/50 & = & -0.07 & [-0.270, 0.134] \\ 
  \{0/25, 25/50, 0/50\} vs. \{25/75, uniform\} & $>$ & 0.34 & [ 0.265, 0.409] \\ 
  25/75 vs. uniform & = & -0.00 & [-0.204, 0.189] \\ 
  \{25/75, uniform\} vs. 0/75 & $>$ & 1.14 & [ 0.903, 1.375] \\ 
  0/75 vs. \{25/100, 50/100\} & $>$ & 1.11 & [ 0.866, 1.352] \\ 
  25/50 vs. 50/100 & = & -0.09 & [-0.297, 0.127] \\ 
  \{25/100, 50/100\} vs. \{75/100, 0/100\} & $>$ & 0.52 & [ 0.307, 0.743] \\ 
  75/100 vs. 0/100 & = & -0.21 & [-0.458, 0.035] \\ 
   \hline
\end{tabular}
\endgroup
\caption{Regression model fits for planned comparisons. Predictions are based on whether the 95\% credible intervals for the generics model prediction overlap.} 
\end{table}

The computational models we articulate do more than just predict the
\emph{mean} implied prevalence; they predict the full distribution of
responses. The model fits in terms of variance-explained and mean
squared errors for the full distribution of responses in shown in Table
2. Unlike in Expts. 1 and 2, it is not obvious which of these models
accounts best for the data. To quantitatively compare the models in
their ability to predict the empirical distributions of responses for
these ten different conditions, we computed the likelihood of the data
under each model by discretizing the empirical distributions and model
predictions into ten equally spaced bins. As is evident from
Figure~\ref{fig:priorManipulationResults}A (bottom row, \enquote{data}),
however, a number of participants responded that 0\% of Ks had the
property. Examining these participants' explanations revealed that the
majority of these respondents believed they were answering a question
more akin to the prior elicitation / manipulation check task: Predict
the next animal. This is a source of noise in the data and one that
affects all models (execept the prior only model) to an equal degree.
All of the models we articulate (the uncertain threshold and the fixed
threshold models) have no way to account for 0\% responses, which is
literally impossible given the utterance of the form \enquote{Ks F}. To
compute the likelihood of the complete data set under these models, we
make the further assumption that the true generative process of the data
is a mixture of responding according to the model and responding
according to the prior. We calculate Bayes Factors assuming a uniform
distribution of noise between 0-20\% (approximated using the following
discretization \(= \{0.001, 0.01, 0.05, 0.1, 0.15, 0.20\}\)). To account
for uncertainty in the measurement of the prior, we again bootstrap the
model predictions by resampling the prior. As if shown in Table 2, the
uncertain threshold model is by far the best model at predicting these
data.

\begin{table}[H]
\centering
\begingroup\fontsize{9pt}{10pt}\selectfont
\begin{tabular}{llll}
  \hline
Model & log Bayes Factor & expected value statistics & full distribution statistics \\ 
  \hline
Threshold = 0.01 & -70.7 (-56.2, -85.5) & r\textsuperscript{2}(10) = 0.91; MSE = 0.0192 & r\textsuperscript{2}(200) = 0.49; MSE = 0.00383 \\ 
  Threshold = 0.1 & -92 (-79.4, -105.2) & r\textsuperscript{2}(10) = 0.79; MSE = 0.0063 & r\textsuperscript{2}(200) = 0.57; MSE = 0.00322 \\ 
  Threshold = 0.35 & -615.3 (-597.4, -632.5) & r\textsuperscript{2}(10) = 0.49; MSE = 0.0225 & r\textsuperscript{2}(200) = 0.37; MSE = 0.00531 \\ 
  Prior & -53.8 (-44, -63.6) & r\textsuperscript{2}(10) = 0.91; MSE = 0.0192 & r\textsuperscript{2}(200) = 0.49; MSE = 0.00383 \\ 
  Uncertain threshold & 0 & r\textsuperscript{2}(10) = 0.89; MSE = 0.00427 & r\textsuperscript{2}(200) = 0.63; MSE = 0.00277 \\ 
   \hline
\end{tabular}
\endgroup
\caption{Summary statistics for alternative generic interpretations. (Log) Bayes Factors quantify evidence in favor of each model in comparison to the uncertain threshold generics model. Numbers less than 0 indicate evidence in favor of the uncertain threshold model. Summary statistics disaplyed for the model fits for the expected values (means) of the distributions and the full (discretized) distributions.} 
\end{table}

\section{General Discussion}\label{general-discussion}

Much of what we come to learn about the world comes from other people,
often expressed in language. Generic language is the foremost case study
of how abstract, generalizable knowledge is transmitted in language.
Despite its ubiquity and relative morphosyntactic simplicity, there have
been few quantitative studies of generics and no quantitative models
that make predictions about how generic language is interpreted. Here we
test a quantitative model on a broad set of quantitative data, including
a replication data set from Cimpian et al. (2010). We find reliable
fine-grained differences in interpretations across properties, which
only our uncertain threshold model can account for. This work, thus,
provides the computational formalism necessary to describe how beliefs
are updated from generic language. In what follows, we provide further
exposition about the empirical data, relate our account to a related
kind of account based on the idea of \emph{domain restriction}, discuss
how our answer to the problem of generic interpretation can inform an
answer to the problem of a parallel problem \emph{generic
identification}, and speculate about the origins of context-sensitive
generic interpretations.

\ndg{i'm not so sure about including these following discussion sections. they seem like interesting but only thematically related, as apposed to being crucial to our story or responses to probably objections. i didn't comment / edit them yet -- let's first decide if they stay.}

\subsection{The relationship between prevalence priors and generic
interpretations}\label{the-relationship-between-prevalence-priors-and-generic-interpretations}

Across our three experiments, we measured participants' background
knowledge about the property using knowledge elicitation tasks that rely
upon the usage of language (e.g., in the instructions and the
elicitation questions). That is, in both the prior elicitation and
generic interpretation task we measure participants' beliefs using
language tasks. The concern for circularity in our argument warrants
further discussion.

The potential for circularity is most apparent with the structured
elicitation task in Expt. 1a. In Expt. 1, we assumed a particular
structure to the prevalence prior and elicited participants' knowledge
about the property using questions that we assumed tapped into this
structure. One question concerned the relative probability mass of the
prevalence distribution around 0\% prevalence (or, equivalently, the
proportion of categories for whom the property is expected to be present
at some non-zero level of prevalence) by asking \enquote{How likely is
it that \emph{there is a K with F}?} Intuitively, the response to this
question should be very high for properties that exist in many
categories (e.g., \emph{is female}) and low for properties that only
exist in a few categories (e.g., \emph{has purple feathers}). The second
question concerned the shape of the non-zero prevalence aspects of the
prior distribution; this was measured by asking \enquote{\emph{Suppose
there is a K with F}, how many Ks do you think have F?}. This question
measures the projectibility of the property given a single, positive
exemplar. Because this question does not include the generic statement
inside of it, the predictions of the \enquote{some} model (which rules
out 0\% prevalence) are derived from background knowledge in the correct
way: They are the inferences upon learning that at least one member of
the category has the property.

The patterns of data we observe in our three generic interpretation
experiments are unlikely to be the same as if participants heard
\enquote{Some Ks have F} rather than \enquote{Ks have F}. Though we did
not empirically measure judgments given the existentially quantified
statements, the alternative model that assumes a fixed-threshold at
0\%-prevalence provides insight into what should be expected for those
data.\footnote{Note that the fixed-threshold models are \enquote{literal
  interpretation} models and do not compute scalar implicatures.} Across
our three experiments, we found that the \enquote{some} model provided
too weak of interpretations, consistent with the intuition that generic
statements convey stronger prevalence implications that the existential
statement.

\ndg{people may worry about circularity of argument, given rich background knowledge elicitation that also uses language (similar to ellen's point). i think we should discuss this directly. relatedly we should discuss the implications of our structured background knowledge (elicitation and results).}
\mht{does that address it?}

\subsection{Domain restriction}\label{domain-restriction}

In this paper, we test a particular model of generic interpretation.
This model use a prior distribution over the prevalence of a feature
across relevant categories and assumes the truth-functional meaning of
the generic is an uncertain threshold on the prevalence. The prevalence
prior distributions, which we elicit from participants, are likely
already influenced by the conceptual knowledge of our participants. For
example, the prevalence priors over properties that have to do with
reproduction (e.g., \emph{have menstrual cycles}, \emph{get erections})
are multi-modal with one mode around 50\%, clearly reflecting
participants' knowledge that these properties are specific to one sex of
the animal. Other formal theories of generic language make use of a
mechanism by which the domain over which the prevalence of the feature
in the category is calculated is contextually restricted (e.g., Cohen,
1999; Declerck, 1991). In such a theory, the statement \enquote{Lorches
have a menstrual cycle} gets evaluated as \enquote{Female lorches have a
menstrual cycle}; under such an account, the prevalence of the feature
would be 100\% (or near 100\%) because 100\% of the \emph{relevant
lorches} (i.e., the females) have a menstrual cycle.

Interestingly, domain restricted interpretations are present in the
empirical data. Several properties about the reproductive behavior of
animals (Expt. 2b) have interpretation distributions that are bimodal.
For example, \enquote{Morseths have a menstrual cycle} is interpreted
primarily as applying to 50\% of morseths (38 out of 64 give a response
between 45\% and 55\%); however, some participants (10 of 64) rate this
as applying to 100\% of morseths.\footnote{The scientifically correct
  term for this is actually an \enquote{estrous cycle}. We are grateful
  to one of our MTurk participants for pointing this out to us.} This
behavior could result from a participant interpreting the question as
pragmatically restricting the domain to only the members of that
category that \emph{could} have the property (e.g., 100\% of female
morseths have a menstrual cycle). The domain restricted interpretation
is not limited to the generic interpretation data, however. We notice
this bimodal interpretation in our prevalence elicitation task (Expt.
2a) as well: The distribution over several of the reproductive
properties is tri-modal, with peaks at 0\% (the animals that don't have
a menstrual cycle), 50\% (\enquote{only females}) and 100\% (perhaps,
\enquote{all females}). The fact that this multi-modality appears in the
prior elicitation task means that the generic interpretation model
predicts bi-modal interpretation distributions for the implied
prevalence data.

From a purely theoretical perspective, domain restriction is an
attractive mechanism because it would allow the semantic theory to be a
context-invariant fixed threhsold (e.g., at 50\%; Cohen, 1999). However,
such a theory still needs to explain why and formalize how the domain
gets restricted; without such a formal account to accompany the domain
restriction hypothesis, the hypothesis explains but does not predict the
data. The uncertain threshold model that we present here can be seen as
a particular instantiation of a domain restriction theory. In our model,
the statement \enquote{Lorches have a menstrual cycle} is resolved by a
literal interpretation model to mean mean \enquote{50\% of lorches have
a menstrual cycle}. Were a listener to have the background theory that
the reason why half of a category would have such a property is for
reproductive purposes, the listener's interpretation would most
naturally be expressed as \enquote{Female lorches have a menstrual
cycle}.

Indeed, this kind of conceptual knowledge is present in our
participants, as evidence by their explanations. One participant wrote:
\enquote{About half are females and females have menstrual cycles.}
Another: \enquote{I assumed that only a percentage of Moxes were female
and young enough to have a menstrual cycle.} A typical explanation of a
participant's response to \emph{Dobles live in zoos} was \enquote{I
thought that there would be many more Dobles in the wild than in zoos.
This is true of most animals in zoos today}. Here, it is clear that the
participant is using their knowledge of the property, derived from other
animals, to learn about the category. Participants often wrote about the
lack of an enabling causal situation when describing their weak
interpretations: \enquote{Most frams don't have access to nicotine.}

Our model restricts the domain by reasoning about a threshold that would
make sense for that particular property, given its background
distribution on prevalence. Reasoning about an uncertain threshold via
background knowledge is one mechanism by which the domain can be
restricted.

\subsection{Generic identification}\label{generic-identification}

It is often noted that bare plurals (e.g., \enquote{Dogs have four
legs}) though often interpreted as generics can also manifest as
\emph{non-generics} (e.g., \enquote{Dogs are on my front lawn}).
Figuring out when a sentence expresses a generic meaning vs.~a
non-generic meaning is called the problem of generic identification is a
parallel challenge to the problem of generic meaning, which we have
addressed in this paper.

Our answer to the question \enquote{what do generics mean?} involves
vagueness concerning the prevalence. Interpreting the uncertain
threshold as a kind of domain restriction might be sufficient to extend
the model to interpreting \enquote{non-generic} bare plurals (e.g.,
\enquote{Dogs are on my front lawn}).

First, let us note that many generics actually expressed two or more
generalizations. For example, \enquote{Lorches eat insects} says that
\([gen \text{ lorches}] [hab \text{ eat}] [gen \text{ insects}]\). In
this paper, we have looked at the first aspect of generic understanding,
the generalization over the head noun category (e.g., lorches) though in
the next chapter we will see that the same uncertain threshold model can
explain habitual language as well (e.g., \enquote{John smokes}). An old
intuition with generics is that at least some express properties that
are especially timeless and enduring ({\textbf{???}}; Gelman, 2003;
Gelman \& Bloom, 2007), though it is not clear what generalization this
should be attributed to. For instance, \enquote{Dogs are on my front
lawn} exhibits only a single generalization (e.g., over \emph{dogs}); it
lacks the habitual verb phrase (\emph{eat}). The habitual aspect of the
verb may influence the expected prevalence in the head noun category:
the more vague, habitual predicate may apply to more instances of the
category (e.g., it's easy to tell whether or not a dog is on your front
lawn, but harder to tell whether or not an animal eats insects
\emph{habitually}). For non-habitual predicates, the expected prevalence
would be substantially more restricted. Thus, we may find continuity in
interpretations of underspecified noun phrases which include so-called
\enquote{non-generics}: \enquote{Tigers have stripes}, \enquote{Tigers
are in the savanna}, \enquote{Tigers are in zoos}, \enquote{Tigers are
in my local zoo}, \enquote{Tigers are on my front lawn}. The uncertain
threshold model may be such a way as to pragmatically infer a continuum
of interpretations, from generics that are interpreted as universals
(\enquote{Tigers are mammals}) to those that are interpreted
existentially but habitually (\enquote{Tigers are in zoos}) to those
that are interpreted existentially and non-habitually (\enquote{Tigers
are on my front lawn}).

\subsection{Development of weak
interpretations}\label{development-of-weak-interpretations}

The experimental data we present provides strong evidence for the
existence of \enquote{weak generics}, which we operationalize here as
generic statements that imply a prevalence less than 50\%. Statements
like \enquote{Lorches live in zoos}, \enquote{Feps perform in the
circus}, and \enquote{Wugs have seizures} all received average implied
prevalence ratings below 50\%, with many individual participants
providing ratings of 10\% or less (Expt. 2b). When manipulating the
prevalence prior distributions to suggest only prevalence levels of
around 0\% or aroud 25\%, participants interpret the statement
\enquote{Ks know when earthquakes are about to happen} to mean about
25\% (Expt. 3b). Adults readily use their causal knowledge of the world
to restrict the interpretation of a generic statement to a reasonable
population, as evidenced by their explanations (a few of which are
described above). This is an aspect of generic language understanding
often swept under the rug: Generics are believed to (in a generic sense)
carry strong implications. Here, we show that generics also carry weak
implications.

It is often argued that children have adult-like understanding of
generics from a very young age
\red{(cite Gelman, Leslie, Brandone, Cimpian)}. These studies often look
at a small range of properties that do not exhibit much
context-sensitivity. It is an open-question whether or not children
understand \enquote{weak generics}.

There are theoretical reasons to think that the understanding of weak
generics may be later developing. Prevalence priors are naturally
modeled as Beta distributions, which are probability distributions over
numbers ranging from 0 - 1: In other words, Beta distributions are
probability distributions over probabilities. These probabilities can be
thought of as the weight of a biased coin, and a common interpretation
of the parameters of the Beta distribution are as \emph{pseudo-counts},
imaginary outcomes of a previous experiment of flipping the coin. For
example, a Beta(1, 9) distribution describes beliefs about the weight of
the coin upon observing 1+9 = 10 flips of that coin, 1 of which landed
on heads and 9 of which landed on tails. This probability distribution
heavily favors numbers around 0.1, as a coin of that weight is most
likely to have generated the observed 1 out of 10 heads.

If we take the pseudo-counts as indices of worldly experience, it is
interesting to note what happens as the pseudo-counts approach 0. As the
parameters approach zero, the Beta probability distribution increasingly
prefers extreme values: 0 or 1. If our knowledge about predictive
probabilities are represented by Beta distributions, then early on, our
belief distributions would favor categorical thinking. However, once we
start to learn about different kinds of categories and properties,
probably via labeling, we may begin to represent multiple distributions
in our prevalence priors. Such a development would predict that children
start out interpreting all generics as strong generics, and that the
understanding of weak generics is later developing ability.

\subsection{Conclusion}\label{conclusion}

Abstract knowledge is transmitted via generic statements but heretofore
no quantitative models have accounted for this belief updating processs.
The uncertain threshold model is able to account for the large
variability in generic interpretations, even predicting the existence of
\enquote{weak generics}, or generics that only apply to a minority of
the category.

\newpage

\section{References}\label{references}

\hypertarget{refs}{}
\hypertarget{ref-Abelson1966}{}
Abelson, R. P., \& Kanouse, D. E. (1966). Subjective acceptance of
verbal generalizations. In S. Feldman (Ed.), \emph{Cognitive
consistency: Motivational antecedents and behavioral consequents} (pp.
171--197). Academic Press.

\hypertarget{ref-Carlson1977}{}
Carlson, G. N. (1977). \emph{Reference to kinds in english}
(PhD thesis). University of Massachusetts, Amherst.

\hypertarget{ref-Cimpian2009:explanations}{}
Cimpian, A., \& Markman, E. M. (2009). Information learned from generic
language becomes central to children's biological concepts: Evidence
from their open-ended explanations. \emph{Cognition}, \emph{113}(1),
14--25.
doi:\href{https://doi.org/10.1016/j.cognition.2009.07.004}{10.1016/j.cognition.2009.07.004}

\hypertarget{ref-Cimpian2010}{}
Cimpian, A., Brandone, A. C., \& Gelman, S. A. (2010). Generic
statements require little evidence for acceptance but have powerful
implications. \emph{Cognitive Science}, \emph{34}(8), 1452--1482.

\hypertarget{ref-Cimpian2010theory}{}
Cimpian, A., Gelman, S. A., \& Brandone, A. C. (2010). Theory-based
considerations influence the interpretation of generic sentences.
\emph{Language and Cognitive Processes}, \emph{25}(2), 261--276.
doi:\href{https://doi.org/10.1080/01690960903025227.Theory-based}{10.1080/01690960903025227.Theory-based}

\hypertarget{ref-Cohen1999}{}
Cohen, A. (1999). Generics, Frequency Adverbs, and Probability.
\emph{Linguistics and Philosophy}, \emph{22}.

\hypertarget{ref-Cohen2004}{}
Cohen, A. (2004). Generics and Mental Representations. \emph{Linguistics
and Philosophy}, \emph{27}(5), 529--556.
doi:\href{https://doi.org/10.1023/B:LING.0000033851.25870.3e}{10.1023/B:LING.0000033851.25870.3e}

\hypertarget{ref-Declerck1991}{}
Declerck, R. (1991). The origins of genericity. \emph{Linguistics},
\emph{29}, 79--102.

\hypertarget{ref-Gelman2003}{}
Gelman, S. A. (2003). \emph{Essential child: Origins of
essentialntialism in everyday thought.} Oxford University Press.

\hypertarget{ref-Gelman2004}{}
Gelman, S. A. (2004). Learning words for kinds: Generic noun phrases in
acquisition. In \emph{Weaving a lexicon} (pp. 445--484). MIT Press.

\hypertarget{ref-Gelman2009}{}
Gelman, S. A. (2009). Learning from others: Children's construction of
concepts. \emph{Annual Review of Psychology}, \emph{60}, 115--140.
doi:\href{https://doi.org/10.1146/annurev.psych.59.103006.093659.LEARNING}{10.1146/annurev.psych.59.103006.093659.LEARNING}

\hypertarget{ref-Gelman2007}{}
Gelman, S. A., \& Bloom, P. (2007). Developmental changes in the
understanding of generics. \emph{Cognition}, \emph{105}(1), 166--183.
doi:\href{https://doi.org/10.1016/j.cognition.2006.09.009}{10.1016/j.cognition.2006.09.009}

\hypertarget{ref-Gelman1998}{}
Gelman, S. A., Coley, J. D., Rosengren, K. S., Hartman, E., \& Pappas,
A. (1998). Beyond labeling: the role of maternal input in the
acquisition of richly structured categories. \emph{Monographs of the
Society for Research in Child Development}, \emph{63}(1), I--V,
1--148;discussion 149--157.

\hypertarget{ref-Gelman2008}{}
Gelman, S. A., Goetz, P. J., Sarnecka, B. W., \& Flukes, J. (2008).
Generic Language in Parent-Child Conversations. \emph{Language Learning
and Development}, \emph{4}(1), 1--31.
doi:\href{https://doi.org/10.1080/15475440701542625.Generic}{10.1080/15475440701542625.Generic}

\hypertarget{ref-Gelman2002}{}
Gelman, S. A., Star, J. R., \& Flukes, J. E. (2002). Children's Use of
Generics in Inductive Inferences. \emph{Journal of Cognition and
Development}, \emph{3}(2), 179--199.

\hypertarget{ref-GelmanEtAl2004}{}
Gelman, S. A., Taylor, M. G., Nguyen, S. P., Leaper, C., \& Bigler, R.
S. (2004). Mother-child conversations about gender: Understanding the
acquisition of essentialist beliefs. \emph{Monographs of the Society for
Research in Child Development}, \emph{69}(1), vii, 116--127.
doi:\href{https://doi.org/10.1111/j.1540-5834.2004.06901001.x}{10.1111/j.1540-5834.2004.06901001.x}

\hypertarget{ref-dippl}{}
Goodman, N. D., \& Stuhlmüller, A. (2014). The Design and Implementation
of Probabilistic Programming Languages. \url{http://dippl.org}.

\hypertarget{ref-Khemlani2009}{}
Khemlani, S., Leslie, S.-J., \& Glucksberg, S. (2009). Generics,
prevalence, and default inferences. In \emph{Proceedings of the 31st
annual conference of the cogntiive science society}. Austin, TX.

\hypertarget{ref-Khemlani2012}{}
Khemlani, S., Leslie, S.-J., \& Glucksberg, S. (2012). Inferences about
members of kinds: The generics hypothesis. \emph{Language and Cognitive
Processes}, \emph{27}(6), 887--900.
doi:\href{https://doi.org/10.1080/01690965.2011.601900}{10.1080/01690965.2011.601900}

\hypertarget{ref-Leslie2008}{}
Leslie, S.-J. (2008). Generics: Cognition and acquisition.
\emph{Philosophical Review}, \emph{117}(1).

\hypertarget{ref-Montague1973}{}
Montague, R. (1973). The Proper Treatment of Quantification in Ordinary
English. In \emph{Philosophy, language, and artificial intelligence}
(pp. 141-----162). Springer. Retrieved from
\url{http://semantics.uchicago.edu/kennedy/classes/s08/semantics2/montague73.pdf}

\hypertarget{ref-Nisbett1983}{}
Nisbett, R. E., Krantz, D. H., Jepson, C., \& Kunda, Z. (1983). The use
of statistical heuristics in everyday inductive reasoning.
\emph{Psychological Review}, \emph{90}(4), 339--363.
doi:\href{https://doi.org/10.1037/0033-295X.90.4.339}{10.1037/0033-295X.90.4.339}

\hypertarget{ref-Prasada2013}{}
Prasada, S., Khemlani, S., Leslie, S.-J., \& Glucksberg, S. (2013).
Conceptual distinctions amongst generics. \emph{Cognition},
\emph{126}(3), 405--22.
doi:\href{https://doi.org/10.1016/j.cognition.2012.11.010}{10.1016/j.cognition.2012.11.010}

\hypertarget{ref-Rhodes2012}{}
Rhodes, M., Leslie, S.-J., \& Tworek, C. M. (2012). Cultural
transmission of social essentialism. \emph{Proceedings of the National
Academy of Sciences}, \emph{109}(34), 13526--13531.
doi:\href{https://doi.org/10.1073/pnas.1208951109}{10.1073/pnas.1208951109}

\hypertarget{ref-Ritchie2016}{}
Ritchie, D., Stuhlmüller, A., \& Goodman, N. D. (2016). C3: Lightweight
incrementalized mcmc for probabilistic programs using continuations and
callsite caching. In \emph{AISTATS 2016}.

\hypertarget{ref-hurdleModels}{}
Rose, C. E., Martin, S. W., Wannemuehler, K. A., \& Plikaytis, B. D.
(2006). On the use of zero-inflated and hurdle models for modeling
vaccine adverse event count data. \emph{Journal of Biopharmaceutical
Statistics}, \emph{16}(4), 463--481.

\hypertarget{ref-Shepard1987}{}
Shepard, R. N. (1987). Toward a universal law of generalization for
psychological science. \emph{Science (New York, N.Y.)},
\emph{237}(4820), 1317--1323.
doi:\href{https://doi.org/10.1126/science.3629243}{10.1126/science.3629243}

\hypertarget{ref-Tenenbaum2011}{}
Tenenbaum, J. B., Kemp, C., Griffiths, T. L., \& Goodman, N. D. (2011).
How to grow a mind: statistics, structure, and abstraction.
\emph{Science (New York, N.Y.)}, \emph{331}(6022), 1279--85.
doi:\href{https://doi.org/10.1126/science.1192788}{10.1126/science.1192788}

\hypertarget{ref-TesslerLangGenUnderReview}{}
Tessler, M. H., \& Goodman, N. D. (under review). The language of
generalization.

\newpage

\section{Appendix: Items}\label{appendix-items}

\begingroup\fontsize{9pt}{10pt}\selectfont

\begin{longtable}{ |p{1in}| |p{1in}|}
  \hline
{\bfseries Property} & {\bfseries Property type} \\ 
  \hline
broken legs & accidental \\ 
   \hline
burned skin & accidental \\ 
   \hline
cracked claws & accidental \\ 
   \hline
dusty skin & accidental \\ 
   \hline
fungus-covered fur & accidental \\ 
   \hline
infected ears & accidental \\ 
   \hline
itchy tails & accidental \\ 
   \hline
muddy feathers & accidental \\ 
   \hline
rotten teeth & accidental \\ 
   \hline
sore legs & accidental \\ 
   \hline
sore teeth & accidental \\ 
   \hline
swollen ears & accidental \\ 
   \hline
torn feathers & accidental \\ 
   \hline
torn tails & accidental \\ 
   \hline
wet fur & accidental \\ 
   \hline
worn-out claws & accidental \\ 
   \hline
blue claws & color \\ 
   \hline
orange ears & color \\ 
   \hline
orange tails & color \\ 
   \hline
pink teeth & color \\ 
   \hline
purple feathers & color \\ 
   \hline
silver legs & color \\ 
   \hline
violet skin & color \\ 
   \hline
yellow fur & color \\ 
   \hline
claws & part \\ 
   \hline
ears & part \\ 
   \hline
feathers & part \\ 
   \hline
fur & part \\ 
   \hline
legs & part \\ 
   \hline
skin & part \\ 
   \hline
tails & part \\ 
   \hline
teeth & part \\ 
   \hline
big claws & vague \\ 
   \hline
curly fur & vague \\ 
   \hline
long legs & vague \\ 
   \hline
long tails & vague \\ 
   \hline
long teeth & vague \\ 
   \hline
rough skin & vague \\ 
   \hline
small ears & vague \\ 
   \hline
smooth feathers & vague \\ 
   \hline
\hline
\caption{Items used in Expt. 1} 
\end{longtable}

\endgroup

\begingroup\fontsize{9pt}{10pt}\selectfont

\begin{longtable}{ |p{3in}|}
  \hline
{\bfseries property} \\ 
  \hline
are afraid of dogs \\ 
   \hline
are afraid of loud noises \\ 
   \hline
are intelligent \\ 
   \hline
attack hikers \\ 
   \hline
attract mates by secreting pheromones \\ 
   \hline
cannibalize each other \\ 
   \hline
capture other animals territory \\ 
   \hline
carry Lyme disease \\ 
   \hline
carry malaria \\ 
   \hline
carry out premeditated murder \\ 
   \hline
chase their tails \\ 
   \hline
develop back problems \\ 
   \hline
develop phobias \\ 
   \hline
do handstands to scare off predators \\ 
   \hline
drink alcohol left behind by tourists \\ 
   \hline
drink soda \\ 
   \hline
eat candy wrappers \\ 
   \hline
eat cannabis \\ 
   \hline
eat garbage \\ 
   \hline
eat grass \\ 
   \hline
eat human food \\ 
   \hline
eat insects \\ 
   \hline
eat people \\ 
   \hline
experience emotions \\ 
   \hline
experience empathy \\ 
   \hline
feed on the carcasses of dead animals \\ 
   \hline
fish in the Hudson River \\ 
   \hline
fly into building windows \\ 
   \hline
get addicted to nicotine \\ 
   \hline
get cancer \\ 
   \hline
get dandruff \\ 
   \hline
get erections \\ 
   \hline
get in fights with other animals \\ 
   \hline
give birth underwater \\ 
   \hline
go bald \\ 
   \hline
have a menstrual cycle \\ 
   \hline
have an exquisite sense of smell \\ 
   \hline
have brown fur \\ 
   \hline
have dozens of sexual partners \\ 
   \hline
have four legs \\ 
   \hline
have intensely beautiful feathers \\ 
   \hline
have personalities \\ 
   \hline
have seizures \\ 
   \hline
have spots \\ 
   \hline
have strange genetic mutations \\ 
   \hline
have very long wings \\ 
   \hline
hunt other animals \\ 
   \hline
know how to open doors \\ 
   \hline
know how to ride bicycles \\ 
   \hline
know when earthquakes are about to happen \\ 
   \hline
lay eggs in other birds nests \\ 
   \hline
lay eggs without needing fertilization \\ 
   \hline
like to cuddle \\ 
   \hline
live in high-rise buildings \\ 
   \hline
live in the hulls of sea vessels \\ 
   \hline
live in trees \\ 
   \hline
live in urban areas \\ 
   \hline
live in zoos \\ 
   \hline
live to be a hundred years old \\ 
   \hline
live to be five hundred years old \\ 
   \hline
live to be twenty years old \\ 
   \hline
lose their teeth \\ 
   \hline
mourn their dead \\ 
   \hline
perform in the circus \\ 
   \hline
play with bottlecaps \\ 
   \hline
pound their chests to display dominance \\ 
   \hline
ride the subway \\ 
   \hline
sing beautiful songs \\ 
   \hline
sleep during the day \\ 
   \hline
steal farmers crops \\ 
   \hline
swim in shallow pools \\ 
   \hline
torture other animals \\ 
   \hline
transmit HIV \\ 
   \hline
transmit rabies \\ 
   \hline
use tools \\ 
   \hline
\hline
\caption{Items used in Expt. 2} 
\end{longtable}

\endgroup






\end{document}
